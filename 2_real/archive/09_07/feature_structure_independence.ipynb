{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature and Structure Independence\n",
    "\n",
    "to Do\n",
    "\n",
    "Fix Features on Diagonal\n",
    "Make running for GNN with separate Features\n",
    "- fix plot colours to fix range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## libs \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "## Keras\n",
    "from keras.layers import Lambda, Input, Dense, Conv2D, Conv2DTranspose, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "## Basic\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Computation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import scipy\n",
    "from scipy.stats.stats import pearsonr \n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Network Processing\n",
    "import networkx as nx\n",
    "from networkx.generators import random_graphs\n",
    "\n",
    "## node colour\n",
    "orig_cmap = plt.cm.PuBu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## supporting functions\n",
    "from support.preprocessing import sort_adjacency, reshape_A, calculate_A_shape, reconstruct_adjacency, pad_matrix, unpad_matrix, prepare_in_out\n",
    "from support.metrics import compute_mig, compute_mi\n",
    "from support.graph_generating import generate_single, generate_manifold, generate_topol_manifold, generate_topol_manifold\n",
    "from support.latent_space import vis2D, visDistr\n",
    "from support.comparing import compare_manifold_adjacency, compare_topol_manifold\n",
    "from support.plotting import shiftedColorMap\n",
    "\n",
    "## graph sampling\n",
    "from sampling import ForestFire, Metropolis_Hastings, Random_Walk, Snowball, Ties, Base_Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_graph(n,p,draw): \n",
    "\n",
    "    g = random_graphs.erdos_renyi_graph(n, p, seed=None, directed=False)\n",
    "\n",
    "    if draw:\n",
    "        f = np.random.rand(n)\n",
    "        orig_cmap = plt.cm.PuBu\n",
    "        fixed_cmap = shiftedColorMap(orig_cmap, start=min(f), midpoint=0.5, stop=max(f), name='fixed')\n",
    "        nx.draw(g, node_color=f, font_color='white', cmap = fixed_cmap)\n",
    "        plt.show()\n",
    "    \n",
    "    return g\n",
    "\n",
    "g = get_graph(n = 10, p = 0.4, draw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     19
    ]
   },
   "outputs": [],
   "source": [
    "def feature_write(a, f, diag_offset):\n",
    "    \n",
    "    row, col = np.diag_indices(f.shape[0])\n",
    "\n",
    "    if diag_offset > -2:  ## only write to adjacency of 2D_conv or MLP used\n",
    "        a = a.astype(float)\n",
    "        \n",
    "        if f.shape[1] == 1:\n",
    "            \n",
    "            ## fill the diagonal with features\n",
    "            a[row, col] = np.squeeze(f)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            a[row,col] = f\n",
    "        \n",
    "    return a\n",
    "\n",
    "\n",
    "def feature_readoff(reconstructed_a, analyzeArgs):\n",
    "    \n",
    "    f = reconstructed_a.diagonal()\n",
    "    if analyzeArgs[\"normalize_feature\"]:\n",
    "        f = (f - np.min(f))/np.ptp(f) ## normalize feature values\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_dependence: p\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1e776d1dd342c9b688d4572023f80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_shape: (16, 16, 1) , output_shape: (16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "def generate_data(dataArgs): \n",
    "    \n",
    "    \n",
    "    ## Data ________________________________\n",
    "\n",
    "    G = np.zeros((dataArgs[\"n_graphs\"], *calculate_A_shape(dataArgs[\"n_max\"], dataArgs[\"diag_offset\"])))\n",
    "    F = np.zeros((dataArgs[\"n_graphs\"], dataArgs[\"n_max\"], dataArgs[\"n_features\"]))\n",
    "    print(\"feature_dependence:\",dataArgs[\"feature_dependence\"] )\n",
    "    \n",
    "    ## Ground Truth Labels ______________________________\n",
    "\n",
    "    T = list()\n",
    "\n",
    "    ## Generate Graph Data_______________________________\n",
    "\n",
    "    for i in tqdm(range(0,dataArgs[\"n_graphs\"])):\n",
    "        \n",
    "        ## Generate Graph Type ______________________________________________\n",
    "\n",
    "        if dataArgs[\"fix_n\"] == True:\n",
    "            n = dataArgs[\"n_max\"] # generate fixed number of nodes n_max\n",
    "        else:\n",
    "            n = random.randint(1, dataArgs[\"n_max\"]) # generate number of nodes n between 1 and n_max and\n",
    "\n",
    "        p = np.random.rand(1)  # float in range 0 - 1 \n",
    "        g = get_graph(n, p, draw = False)\n",
    "        \n",
    "        \n",
    "        ## Generate / Load Node Features ______________________________________________\n",
    "\n",
    "        if dataArgs[\"feature_dependence\"] == \"random\":\n",
    "            f = np.random.rand(n, dataArgs[\"n_features\"])                   ## float\n",
    "            #F[i] = np.random.randint(2, size=(dataArgs[\"n_max\"],dataArgs[\"n_features\"]))   ## int\n",
    "            \n",
    "        if dataArgs[\"feature_dependence\"] == \"degree\":\n",
    "            if dataArgs[\"n_features\"] == 1:\n",
    "                \n",
    "                f = np.asarray([int(x[1]) for x in g.degree()])   ## sort features by node degree\n",
    "                f = (f+1) / max(f+1)\n",
    "                f = np.reshape(f, (f.shape[-1],1))\n",
    "                \n",
    "        if dataArgs[\"feature_dependence\"] == \"p\":  \n",
    "            if dataArgs[\"n_features\"] == 1:\n",
    "                f = np.ones((n ,1)) * p\n",
    "                \n",
    "        ## padding feature vector with zeroes\n",
    "        if dataArgs[\"n_max\"] - f.shape[0] > 0:\n",
    "            zeroes = np.zeros((dataArgs[\"n_max\"] - f.shape[0], 1))\n",
    "            f = np.concatenate((f, zeroes))\n",
    "        \n",
    "        #nx.draw(g, cmap=plt.get_cmap('PuBu'), node_color=np.squeeze(f), font_color='white')\n",
    "        #plt.show()\n",
    "        \n",
    "        g, a = sort_adjacency(g)\n",
    "        a = pad_matrix(a, dataArgs[\"n_max\"], dataArgs[\"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "        a = feature_write(a, f, dataArgs[\"diag_offset\"])\n",
    "        \n",
    "        a_transformed = reshape_A(a, diag_offset = dataArgs[\"diag_offset\"])\n",
    "        \n",
    "\n",
    "        ## Build Data Arrays___________________________________________________\n",
    "\n",
    "        F[i] = f\n",
    "        G[i] = a_transformed\n",
    "\n",
    "        t = dict()\n",
    "        t[\"n\"] = n\n",
    "        t[\"p\"] = p\n",
    "        \n",
    "        T.append(t)\n",
    "\n",
    "\n",
    "\n",
    "    ## Input and Output Size ___________________________________________________________\n",
    "\n",
    "    T, input_shape, output_shape = prepare_in_out(T, dataArgs[\"diag_offset\"], calculate_A_shape(dataArgs[\"n_max\"], dataArgs[\"diag_offset\"]))\n",
    "    print(\"input_shape:\", input_shape, \", output_shape:\", output_shape)\n",
    "    \n",
    "    ## scale features in F for smoother training\n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(F)\n",
    "    #F = scaler.transform(F)\n",
    "    \n",
    "    return G,T,F,input_shape,output_shape\n",
    "    \n",
    "dataArgs = {\"n_graphs\": 10000, \"n_max\": 16, \"fix_n\": False, \"diag_offset\": -2, \"diag_value\": 1, \"clip\": False, \"n_features\": 1, \"feature_dependence\": \"p\"}  #\"diag_offset\" - 1 == full adjacency\n",
    "G, T, F, input_shape, output_shape = generate_data(dataArgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beta-VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     25,
     243
    ]
   },
   "outputs": [],
   "source": [
    "## Model Setup\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "## Keras\n",
    "from keras.layers import Lambda, Input, Dense, Conv2D, Conv2DTranspose, Flatten, Reshape, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from support.keras_dgl.utils import *\n",
    "from support.keras_dgl.layers import MultiGraphCNN\n",
    "\n",
    "\n",
    "class VAE():\n",
    "\n",
    "    # reparameterization trick\n",
    "    # instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "    # then z = z_mean + sqrt(var)*eps\n",
    "\n",
    "    def sampling(self, args):\n",
    "        \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "        # Arguments\n",
    "            args (tensor): mean and log of variance of Q(z|X)\n",
    "        # Returns\n",
    "            z (tensor): sampled latent vector\n",
    "        \"\"\"\n",
    "\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean=0 and std=1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    \n",
    "    def __init__(self, modelArgs, trainArgs, g_train, g_test, f_train, f_test):\n",
    "\n",
    "        ## MODEL ______________________________________________________________\n",
    "\n",
    "        ## Multi-layer Perceptron without convolutions__________________________________\n",
    "        if modelArgs[\"nn_architecture\"] == \"mlp\":\n",
    "            ## 1) build encoder model __________________________\n",
    "\n",
    "            inputs = Input(shape=modelArgs[\"input_shape\"], name='encoder_input')\n",
    "            x = Dense(128, activation='relu')(inputs)\n",
    "            x = Dense(64, activation='relu')(x)\n",
    "            z_mean = Dense(modelArgs[\"latent_dim\"], name='z_mean')(x)\n",
    "            z_log_var = Dense(modelArgs[\"latent_dim\"], name='z_log_var')(x)\n",
    "\n",
    "            # use reparameterization trick to push the sampling out as input\n",
    "            # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "            z = Lambda(self.sampling, output_shape=(modelArgs[\"latent_dim\"],), name='z')([z_mean, z_log_var])\n",
    "\n",
    "            ## 2) build decoder model __________________________\n",
    "\n",
    "            latent_inputs = Input(shape=(modelArgs[\"latent_dim\"],), name='z_sampling')\n",
    "            y = Dense(64, activation='relu')(latent_inputs)\n",
    "            y = Dense(128, activation='relu')(y)\n",
    "            graph_outputs = Dense(modelArgs[\"output_shape\"], activation='sigmoid')(y)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        ## Convolutional Neural Network_________________________________\n",
    "\n",
    "        if modelArgs[\"nn_architecture\"] == \"2D_conv\":\n",
    "\n",
    "            ## 1) build encoder model____________________________________\n",
    "\n",
    "            inputs = Input(shape=modelArgs[\"input_shape\"], name='encoder_input')\n",
    "            x = inputs\n",
    "\n",
    "            for i in range(2):\n",
    "                modelArgs['filters'] *= 2\n",
    "                x = Conv2D(filters=modelArgs['filters'], kernel_size=modelArgs['kernel_size'], activation='relu', strides=2, padding='same')(x)\n",
    "\n",
    "            # shape info needed to build decoder model\n",
    "            shape = K.int_shape(x)\n",
    "\n",
    "            # generate latent vector Q(z|X)\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "            z_mean = Dense(modelArgs[\"latent_dim\"], name='z_mean')(x)\n",
    "            z_log_var = Dense(modelArgs[\"latent_dim\"], name='z_log_var')(x)\n",
    "\n",
    "            # use reparameterization trick to push the sampling out as input\n",
    "            # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "            z = Lambda(self.sampling, output_shape=(modelArgs[\"output_shape\"],), name='z')([z_mean, z_log_var])\n",
    "\n",
    "            ## 2) build decoder model____________________________________\n",
    "\n",
    "            latent_inputs = Input(shape=(modelArgs[\"latent_dim\"],), name='z_sampling')\n",
    "            x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "            x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "            for i in range(2):\n",
    "                x = Conv2DTranspose(filters=modelArgs['filters'], kernel_size=modelArgs['kernel_size'], activation='relu', strides=2, padding='same')(x)\n",
    "                modelArgs['filters'] //= 2\n",
    "\n",
    "            graph_outputs = Conv2DTranspose(filters=1, kernel_size=modelArgs['kernel_size'], activation='sigmoid',padding='same', name='decoder_output')(x)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        ## Graph Neural Network Architecture __________________________________\n",
    "\n",
    "        if modelArgs[\"nn_architecture\"] == \"gnn\":\n",
    "\n",
    "            ## 1) build encoder model____________________________________\n",
    "\n",
    "            # build graph_conv_filters\n",
    "            SYM_NORM = True\n",
    "            num_filters = 2\n",
    "            print(\"g_train shape:\", g_train.shape)\n",
    "            graph_conv_filters = preprocess_adj_tensor_with_identity(np.squeeze(g_train), SYM_NORM)\n",
    "\n",
    "            \n",
    "            # build model\n",
    "            X_input = Input(shape=(f_train.shape[1], f_train.shape[2]))\n",
    "            graph_conv_filters_input = Input(shape=(graph_conv_filters.shape[1], graph_conv_filters.shape[2]))\n",
    "            \n",
    "            \n",
    "            # define inputs of features and graph topologies\n",
    "            inputs = [X_input, graph_conv_filters_input]\n",
    "\n",
    "            x = MultiGraphCNN(100, num_filters, activation='elu')([X_input, graph_conv_filters_input])\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = MultiGraphCNN(100, num_filters, activation='elu')([x, graph_conv_filters_input])\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Lambda(lambda x: K.mean(x, axis=1))(x)  # adding a node invariant layer to make sure output does not depends upon the node order in a graph.\n",
    "            z_mean = Dense(modelArgs[\"latent_dim\"], name='z_mean')(x)\n",
    "            z_log_var = Dense(modelArgs[\"latent_dim\"], name='z_log_var')(x)\n",
    "\n",
    "            # use reparameterization trick to push the sampling out as input\n",
    "            # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "            z = Lambda(self.sampling, output_shape=(modelArgs[\"latent_dim\"],), name='z')([z_mean, z_log_var])\n",
    "\n",
    "            \n",
    "            ## 2) build decoder model __________________________\n",
    "\n",
    "            ## shape info needed to build decoder model\n",
    "            inputs_2D_encoder = Input(shape=modelArgs[\"input_shape\"], name='encoder_input')\n",
    "            x_2D = inputs_2D_encoder\n",
    "            for i in range(2):\n",
    "                modelArgs['filters'] *= 2\n",
    "                x_2D = Conv2D(filters=modelArgs['filters'], kernel_size=modelArgs['kernel_size'], activation='relu',strides=2, padding='same')(x_2D)\n",
    "            shape_2D = K.int_shape(x_2D)\n",
    "\n",
    "            latent_inputs = Input(shape=(modelArgs[\"latent_dim\"],), name='z_sampling')\n",
    "            x_2D = Dense(shape_2D[1] * shape_2D[2] * shape_2D[3], activation='relu')(latent_inputs)\n",
    "            x_2D = Reshape((shape_2D[1], shape_2D[2], shape_2D[3]))(x_2D)\n",
    "\n",
    "            for i in range(2):\n",
    "                x_2D = Conv2DTranspose(filters=modelArgs['filters'], kernel_size=modelArgs['kernel_size'],activation='relu', strides=2, padding='same')(x_2D)\n",
    "                modelArgs['filters'] //= 2\n",
    "\n",
    "            graph_outputs = Conv2DTranspose(filters=1, kernel_size=modelArgs['kernel_size'], activation='sigmoid',padding='same', name='decoder_output')(x_2D)\n",
    "\n",
    "    \n",
    "    \n",
    "        ## INSTANTIATE___________________________________\n",
    "\n",
    "        ## 1) instantiate encoder model\n",
    "        encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "        encoder.summary()\n",
    "        # plot_model(encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n",
    "\n",
    "        ## 2) instantiate decoder model\n",
    "        graph_decoder = Model(latent_inputs, graph_outputs, name='decoder')\n",
    "        graph_decoder.summary()\n",
    "        # plot_model(decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n",
    "\n",
    "        ## 3) instantiate VAE model\n",
    "        outputs = graph_decoder(encoder(inputs)[2])\n",
    "        vae = Model(inputs, outputs, name='conv_vae')\n",
    "        # vae.summary()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        ## LOSS FUNCTIONS ______________________________________\n",
    "        \n",
    "        def reconstr_loss_func(y_true, y_pred):\n",
    "\n",
    "            ## RECONSTRUCTION LOSS_______________________\n",
    "\n",
    "            if trainArgs[\"loss\"] == \"mse\":\n",
    "\n",
    "                if modelArgs[\"nn_architecture\"] == \"mlp\":\n",
    "                    reconstruction_loss = mse(y_true[0], y_pred[0])\n",
    "                    reconstruction_loss *= modelArgs[\"input_shape\"]\n",
    "\n",
    "                elif modelArgs[\"nn_architecture\"] == \"2D_conv\" or \"gnn\":\n",
    "                    reconstruction_loss = mse(K.flatten(y_true[0]), K.flatten(y_pred[0]))\n",
    "                    reconstruction_loss *= modelArgs[\"input_shape\"][0] * modelArgs[\"input_shape\"][1]\n",
    "\n",
    "            if trainArgs[\"loss\"] == \"binary_crossentropy\":\n",
    "\n",
    "                if modelArgs[\"nn_architecture\"] == \"mlp\":\n",
    "                    reconstruction_loss = binary_crossentropy(y_true[0], y_pred[0])\n",
    "                    reconstruction_loss *= modelArgs[\"input_shape\"]\n",
    "\n",
    "                elif modelArgs[\"nn_architecture\"] == \"2D_conv\" or \"gnn\":\n",
    "                    print(y_true[0], y_pred[0])\n",
    "                    reconstruction_loss = binary_crossentropy(K.flatten(y_true[0]), K.flatten(y_pred[0]))\n",
    "                    reconstruction_loss *= modelArgs[\"input_shape\"][0] * modelArgs[\"input_shape\"][1]\n",
    "\n",
    "                    \n",
    "            ## KL LOSS _____________________________________________\n",
    "\n",
    "            kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "            kl_loss = K.sum(kl_loss, axis=-1)\n",
    "            kl_loss *= -0.5\n",
    "\n",
    "            \n",
    "            ## COMPLETE LOSS __________________________________________________\n",
    "\n",
    "            reconstr_loss = K.mean(reconstruction_loss + (trainArgs[\"beta\"] * kl_loss))\n",
    "\n",
    "            return reconstr_loss\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        ## MODEL COMPILE______________________________________________\n",
    "        \n",
    "        vae.compile(optimizer='adam', loss=reconstr_loss_func, metrics=['mae'])\n",
    "        vae.summary()\n",
    "        \n",
    "        \n",
    "\n",
    "        ## TRAIN______________________________________________\n",
    "\n",
    "        # load the autoencoder weights\n",
    "\n",
    "        if trainArgs[\"weights\"] == \"load\":\n",
    "\n",
    "            vae.load_weights(\"models/weights/vae_mlp_mnist_latent_dim_\" + str(modelArgs[\"latent_dim\"]) + \".h5\")\n",
    "\n",
    "        # train the autoencoder\n",
    "\n",
    "        elif trainArgs[\"weights\"] == \"train\":\n",
    "\n",
    "            # Set callback functions to early stop training and save the best model so far\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=trainArgs[\"early_stop\"]), ModelCheckpoint(filepath=\"models/weights/vae_mlp_mnist_latent_dim_\" + str(modelArgs[\"latent_dim\"]) + \".h5\",save_best_only=True)]\n",
    "\n",
    "            if modelArgs[\"nn_architecture\"] == \"gnn\":\n",
    "\n",
    "                # build graph_conv_filters\n",
    "                SYM_NORM = True\n",
    "                g_train_mod = preprocess_adj_tensor_with_identity(np.squeeze(g_train), SYM_NORM)\n",
    "                g_test_mod = preprocess_adj_tensor_with_identity(np.squeeze(g_test), SYM_NORM)\n",
    "\n",
    "                vae.fit([f_train, g_train_mod], [g_train], epochs=trainArgs[\"epochs\"],batch_size=trainArgs[\"batch_size\"], callbacks=callbacks,validation_data=([f_test, g_test_mod], [g_test]))\n",
    "                vae.save_weights(\"models/weights/vae_mlp_mnist_latent_dim_\" + str(modelArgs[\"latent_dim\"]) + \".h5\")\n",
    "                \n",
    "                models = (encoder, graph_decoder)\n",
    "                data = ([g_test_mod, g_test], f_test)\n",
    "\n",
    "            elif modelArgs[\"nn_architecture\"] == \"2D_conv\" or \"mlp\":\n",
    "\n",
    "                vae.fit(g_train, [g_train], epochs=trainArgs[\"epochs\"], batch_size=trainArgs[\"batch_size\"], callbacks=callbacks, validation_data=(g_test, [g_test]))\n",
    "                vae.save_weights(\"models/weights/vae_mlp_mnist_latent_dim_\" + str(modelArgs[\"latent_dim\"]) + \".h5\")\n",
    "                \n",
    "                models = (encoder, graph_decoder)\n",
    "                data = (g_test, f_test)\n",
    "           \n",
    "        self.model = models\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_train shape: (8000, 16, 16, 1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32, 16)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_graph_cnn_1 (MultiGraphCN (None, 16, 100)      300         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 100)      0           multi_graph_cnn_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "multi_graph_cnn_2 (MultiGraphCN (None, 16, 100)      20100       dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 100)      0           multi_graph_cnn_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            202         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            202         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,804\n",
      "Trainable params: 20,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              3072      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv2DTransp (None, 16, 16, 1)         289       \n",
      "=================================================================\n",
      "Total params: 58,753\n",
      "Trainable params: 58,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32, 16)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 2), (None, 2 20804       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 16, 16, 1)    58753       encoder[1][2]                    \n",
      "==================================================================================================\n",
      "Total params: 79,557\n",
      "Trainable params: 79,557\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 5s 634us/step - loss: 30.7780 - mean_absolute_error: 0.2221 - val_loss: 24.7314 - val_mean_absolute_error: 0.1576\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 4s 519us/step - loss: 20.3870 - mean_absolute_error: 0.1388 - val_loss: 19.2382 - val_mean_absolute_error: 0.1493\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 4s 534us/step - loss: 18.8891 - mean_absolute_error: 0.1327 - val_loss: 18.8157 - val_mean_absolute_error: 0.1289\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 5s 584us/step - loss: 19.4095 - mean_absolute_error: 0.1313 - val_loss: 17.9764 - val_mean_absolute_error: 0.1382\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 5s 585us/step - loss: 18.4983 - mean_absolute_error: 0.1317 - val_loss: 19.0635 - val_mean_absolute_error: 0.1462\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 5s 612us/step - loss: 18.9095 - mean_absolute_error: 0.1286 - val_loss: 18.7322 - val_mean_absolute_error: 0.1348\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 4s 549us/step - loss: 17.0177 - mean_absolute_error: 0.1249 - val_loss: 17.6585 - val_mean_absolute_error: 0.1241\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 4s 527us/step - loss: 18.7830 - mean_absolute_error: 0.1259 - val_loss: 18.1398 - val_mean_absolute_error: 0.1236\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 4s 550us/step - loss: 18.0576 - mean_absolute_error: 0.1267 - val_loss: 18.1005 - val_mean_absolute_error: 0.1205\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 4s 550us/step - loss: 19.0989 - mean_absolute_error: 0.1284 - val_loss: 17.7765 - val_mean_absolute_error: 0.1292\n"
     ]
    }
   ],
   "source": [
    "modelArgs = {\"nn_architecture\": \"gnn\", \"latent_dim\": 2, \"filters\": 16, \"kernel_size\": 3, \"input_shape\": input_shape, \"output_shape\": output_shape, \"param_loss\": False,}\n",
    "trainArgs = {\"beta\": 1, \"loss\": \"mse\", \"weights\": \"train\", \"early_stop\": 3, \"batch_size\": 12, \"epochs\": 50, \"data_split\": 0.2}\n",
    "\n",
    "\n",
    "## Train and Validation Split _______________________________________________\n",
    "g_train, g_test, f_train, f_test = train_test_split(G, F, test_size=trainArgs[\"data_split\"],random_state=1, shuffle=True)\n",
    "\n",
    "\n",
    "vae = VAE(modelArgs, trainArgs, g_train, g_test, f_train, f_test)\n",
    "\n",
    "models = vae.model \n",
    "data = vae.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unpad the adjacency matrix by looking at diagonal values\n",
    "\n",
    "def unpad_matrix(max_adjacency, node_margin, diag_offset, fix_n):\n",
    "    if fix_n == False:\n",
    "\n",
    "        keep = list()\n",
    "        for i in range(0, max_adjacency.shape[0]):\n",
    "            if diag_offset > -2:\n",
    "                if max_adjacency[i][i] > node_margin:\n",
    "                    keep.append(i)\n",
    "            if diag_offset == -2:\n",
    "                if max_adjacency[i][i] > 1 - node_margin:\n",
    "                    print(print(max_adjacency[i][i]))\n",
    "                    keep.append(i)\n",
    "\n",
    "        ## delete rows and columns\n",
    "        max_adjacency = max_adjacency[:, keep]  # keep columns\n",
    "        max_adjacency = max_adjacency[keep, :]  # keep rows\n",
    "\n",
    "    return max_adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-f646873566af>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-f646873566af>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    reconstructed_a = unpad_matrix(reconstructed_a, 2dataArgs[\"diag_offset\"], dataArgs[\"fix_n\"])\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def generate_single_features(analyzeArgs, modelArgs, dataArgs, models):\n",
    "    \n",
    "    encoder, graph_decoder = models  # trained models\n",
    "\n",
    "    print(\"latent dimensions:\", modelArgs[\"latent_dim\"])\n",
    "\n",
    "    z_sample = np.zeros(modelArgs[\"latent_dim\"])\n",
    "    z_sample = np.reshape(z_sample, (1, modelArgs[\"latent_dim\"]))\n",
    "\n",
    "    for i, dim in enumerate(analyzeArgs[\"z\"]):\n",
    "        z_sample[0][dim] = analyzeArgs[\"activations\"][i]\n",
    "\n",
    "    x_decoded = graph_decoder.predict(z_sample)\n",
    "\n",
    "    ## reconstruct upper triangular adjacency matrix\n",
    "    reconstructed_a = reconstruct_adjacency(x_decoded, dataArgs[\"clip\"], dataArgs[\"diag_offset\"])\n",
    "    \n",
    "    ## read off the node features\n",
    "    reconstructed_a = unpad_matrix(reconstructed_a, 2dataArgs[\"diag_offset\"], dataArgs[\"fix_n\"])\n",
    "    f = feature_readoff(reconstructed_a, analyzeArgs)\n",
    "    print(\"features:\", f)\n",
    "\n",
    "    print(reconstructed_a.shape)\n",
    "    print(f.shape)\n",
    "    \n",
    "    ## reconstruct graph\n",
    "    g = nx.from_numpy_matrix(reconstructed_a)\n",
    "    fixed_cmap = shiftedColorMap(orig_cmap, start=min(f), midpoint=0.5, stop=max(f), name='fixed')\n",
    "    nx.draw(g, node_color=f, font_color='white', cmap = fixed_cmap)\n",
    "    plt.show()\n",
    "    \n",
    "    ax = sns.distplot(f, rug = True)\n",
    "    ax.set_title('Node Feature Distribution', fontweight = \"bold\")\n",
    "    ax.set(xlabel=\"feature value\", ylabel=\"frequency\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzeArgs = {\"z\": [0,1], \"activations\": [-10,+10], \"normalize_feature\": True}\n",
    "generate_single_features(analyzeArgs, modelArgs, dataArgs, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Structure or Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def latent_space_feature_correlation(analyzeArgs, modelArgs, models, data, batch_size=128,model_name=\"vae_graph\"):\n",
    "\n",
    "    \n",
    "    ## unpack models and data__________________________\n",
    "    \n",
    "    encoder, graph_decoder = models  # trained models\n",
    "    A, F = data\n",
    "    if modelArgs[\"nn_architecture\"] == \"gnn\":\n",
    "        A_mod, A = A\n",
    "                \n",
    "    mod_degree = np.linspace(0,dataArgs[\"n_max\"],analyzeArgs[\"n_config_graphs\"], dtype = int)      \n",
    "        \n",
    "    ## topol parameters\n",
    "    topol_params = [\"density\", \"diameter\", \"cluster_coef\", \"assort\", \"#edges\", \"avg_degree\"]\n",
    "\n",
    "    ## store graphs and targets\n",
    "    # shape: n_config_graphs, params, upper_A_size\n",
    "    A_mod = np.zeros((analyzeArgs[\"n_config_graphs\"], *calculate_A_shape(dataArgs[\"n_max\"], dataArgs[\"diag_offset\"])))\n",
    "    F_mod = np.zeros((analyzeArgs[\"n_config_graphs\"], dataArgs[\"n_max\"], dataArgs[\"n_features\"]))\n",
    "    \n",
    "\n",
    "    for i, (a, f) in enumerate(zip(A[:analyzeArgs[\"n_config_graphs\"]], F[:analyzeArgs[\"n_config_graphs\"]])):\n",
    "\n",
    "        ## Generate Graph Type ______________________________________________\n",
    "            \n",
    "        #f = feature_readoff(a, analyzeArgs) # read off the features\n",
    "        a = reconstruct_adjacency(np.squeeze(a), dataArgs[\"clip\"], dataArgs[\"diag_offset\"])\n",
    "        a = unpad_matrix(a, dataArgs[\"diag_value\"], dataArgs[\"fix_n\"])\n",
    "        \n",
    "        if analyzeArgs[\"f_variation\"] == \"random\":\n",
    "\n",
    "            for mod in range(0, mod_degree[i]):\n",
    "                swap = np.random.randint(low = 0, high = f.shape[0], size = 2)\n",
    "                temp = f[swap[0]]\n",
    "                f[swap[0]] = f[swap[1]]\n",
    "                f[swap[1]] = temp\n",
    "                \n",
    "                \n",
    "        elif analyzeArgs[\"f_variation\"] == \"equal\":\n",
    "    \n",
    "            norm_std = mod_degree[i] / max(mod_degree)\n",
    "            norm_mean = np.mean(f) \n",
    "            \n",
    "            for i in range(0,len(f)):\n",
    "                \n",
    "                if f[i] > norm_mean:\n",
    "                    f[i] = f[i] - (norm_std * (np.abs(f[i] - norm_mean)))\n",
    "                else:\n",
    "                    f[i] = f[i] + (norm_std * (np.abs(f[i] - norm_mean )))\n",
    "                    \n",
    "                    \n",
    "        elif analyzeArgs[\"f_variation\"] == \"uniform\":\n",
    "    \n",
    "            f = np.ones(f.shape[0]) * (mod_degree[i] / max(mod_degree))\n",
    "            f = np.reshape(f, (f.shape[-1],1))\n",
    "                    \n",
    "        F_mod[i] = f\n",
    "    \n",
    "        a_mod = pad_matrix(a, dataArgs[\"n_max\"], dataArgs[\"diag_value\"])\n",
    "        a_mod = feature_write(a_mod, f, dataArgs[\"diag_offset\"])  # write the modified feature to adjacency\n",
    "\n",
    "        upper_a_mod = reshape_A(a_mod, dataArgs[\"diag_offset\"])\n",
    "        A_mod[i] = upper_a_mod\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    ## ENCODER - 2D Digit Classes ______________________________________________\n",
    "    \n",
    "    if modelArgs[\"nn_architecture\"] == \"gnn\":\n",
    "        print(\"gnn\")\n",
    "        # build graph_conv_filters\n",
    "        SYM_NORM = True\n",
    "        g_train_mod = preprocess_adj_tensor_with_identity(np.squeeze(A_mod), SYM_NORM)\n",
    "        z_mean, _, _ = encoder.predict([F_mod, g_train_mod], batch_size = batch_size)\n",
    "\n",
    "    elif modelArgs[\"nn_architecture\"] == \"2D_conv\" or \"mlp\":\n",
    "        print(\"2D_conv or mlp\")\n",
    "        # display a 2D plot of the digit classes in the latent space\n",
    "        z_mean, _, _ = encoder.predict(A, batch_size = batch_size)\n",
    "\n",
    "\n",
    "    ## Measure the Mutual Information Gap ____________________________________________\n",
    "    if analyzeArgs[\"metric\"] == \"mig\":\n",
    "        mig = compute_mig(mod_degree, np.squeeze(z_mean))\n",
    "        \n",
    "        \n",
    "    ## toDO: measure the correlation between latent variable and the generative factor / features\n",
    "\n",
    "    ## Visualize Latent Variables x Feature Change ____________________________\n",
    "\n",
    "    fig, ax = plt.subplots(nrows= z_mean.shape[-1] , ncols= 1)\n",
    "\n",
    "    for latent_z, row in enumerate(ax):        \n",
    "\n",
    "            y = z_mean[:,latent_z]\n",
    "            x = mod_degree / mod_degree.shape[0]\n",
    "            sns.regplot(x, y, color=\"steelblue\", ax=row)\n",
    "\n",
    "            ## compute correlation and standardized covariance\n",
    "            corr = round(pearsonr(x,y)[0],3)\n",
    "            cov = round(np.cov(x, y)[0][1]/max(x),3)\n",
    "            row.annotate(\"corr:\"+str(corr)+\", cov:\"+str(cov), xy=(0, 1), xytext=(12, -12), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "            \n",
    "\n",
    "    ## add row and column titles _____________________\n",
    "\n",
    "    rows = ['z_{}'.format(row) for row in range(z_mean.shape[-1])]\n",
    "    cols = [t for t in [\"feature modification: \" + str(analyzeArgs[\"f_variation\"])]]\n",
    "\n",
    "    for axis, col in zip(ax, cols):\n",
    "        axis.set_title(col, fontweight='bold')\n",
    "\n",
    "    for axis, row in zip(ax, rows):\n",
    "        axis.set_ylabel(row, rotation=0, size='large', fontweight='bold')\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "## PLOT RESULTS ________________________________________\n",
    "\n",
    "analyzeArgs = {\"n_config_graphs\": 60, \"f_variation\": \"uniform\", \"metric\": \"none\"}\n",
    "latent_space_feature_correlation(analyzeArgs, modelArgs, models, data, batch_size=trainArgs[\"batch_size\"], model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
