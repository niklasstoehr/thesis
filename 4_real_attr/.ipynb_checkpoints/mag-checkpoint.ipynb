{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Academic Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess MAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import pandas as pd \n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Network Processing\n",
    "\n",
    "## networkx\n",
    "import networkx as nx\n",
    "from networkx.generators import random_graphs\n",
    "from networkx.generators import social\n",
    "from networkx.generators import classic\n",
    "\n",
    "\n",
    "## smallworld\n",
    "from smallworld.draw import draw_network\n",
    "from smallworld import get_smallworld_graph\n",
    "\n",
    "## snap\n",
    "color_map =[\"grey\"]\n",
    "\n",
    "## graph sampling\n",
    "from sampling import ForestFire, Metropolis_Hastings, Random_Walk, Snowball, Ties, Base_Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/mag/mag_raw.txt','r') \n",
    "\n",
    "L = list()\n",
    "A = defaultdict(int) # default value of int is 0\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "n_list = list()\n",
    "\n",
    "while line:\n",
    "    \n",
    "    if \"#@\" in line:\n",
    "        n_list = line.replace(\"\\n\", \"\").split(\"#@\")[1].split(\",\")\n",
    "        \n",
    "        ## edges\n",
    "        if len(n_list) > 1: \n",
    "            for i in range(0, len(n_list)):\n",
    "                for j in range(i+1, len(n_list)):\n",
    "                        L.append((n_list[i], n_list[j]))                \n",
    "        else:\n",
    "            L.append((n_list[0], n_list[0]))\n",
    "            \n",
    "            \n",
    "                        \n",
    "    if \"#citation\" in line:\n",
    "        \n",
    "        c = line.split(\"#citation\")[1]\n",
    "        c = abs(int(c))\n",
    "        \n",
    "        for n in n_list:\n",
    "            A[n] +=  c\n",
    "                \n",
    "            #print(\"n\", n, \"c\", A[n], \"\\n\")\n",
    "    \n",
    "    line = f.readline() ## read next line\n",
    "\n",
    "f.close()\n",
    "\n",
    "## pre-process and sort\n",
    "L = set(L)\n",
    "\n",
    "A_sorted = sorted(A.items(), key=operator.itemgetter(1), reverse=True)\n",
    "A_sorted = [n_a[0] for n_a in A_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5366282\n",
      "['Jos√© A. Blakeley', 'Yuri Breitbart', 'Hector Garcia-Molina', 'Abraham Silberschatz', 'Tom C. Reyes', 'Stavros Christodoulakis', 'Leonidas Koveos', 'Umeshwar Dayal', 'Eric N. Hanson', 'Jennifer Widom', 'Angelika Kotz Dittrich', 'Klaus R. Dittrich', 'Meichun Hsu', 'Nathan Goodman', 'Gail E. Kaiser', 'William Kelley', 'Sunit K. Gala', 'Won Kim', 'Bruce Graham', 'Alfons Kemper', 'Guido Moerkotte', 'Injun Choi', 'Mark Scheevel', 'Jorge F. Garza', 'Vincent J. Kowalski', 'David Krieger', 'Tim Andrews', 'Teresa F. Lunt', 'Weiyi Meng', 'Clement T. Yu']\n",
      "38608\n",
      "Anil K. Jain\n",
      "1274360\n"
     ]
    }
   ],
   "source": [
    "print(len(L))\n",
    "print(list(A.keys())[:30])\n",
    "print(A[\"Leslie Lamport\"])\n",
    "print(A_sorted[2])\n",
    "print(len(A_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numberize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = list(range(0, len(A_sorted)))\n",
    "num_author = dict(zip(Num, A_sorted))\n",
    "author_num = dict(zip(A_sorted, Num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in L:\n",
    "    L_num.append((author_num[l[0]], author_num[l[1]]))\n",
    "    Source_num.append(author_num[l[0]])\n",
    "    Target_num.append(author_num[l[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Num:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Num:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Num,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes_py.csv\", index = None, header=False)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges_py.csv\", index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274330</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274331</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274332</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274333</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274334</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274335</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274336</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274338</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274339</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274340</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274341</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274342</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274343</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274344</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274345</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274346</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274347</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274348</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274349</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274350</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274351</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274352</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274353</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274354</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274355</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274356</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274357</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274358</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274359</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274360 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  citations\n",
       "Id                      \n",
       "0           1          1\n",
       "1           1          1\n",
       "2           1          1\n",
       "3           1          1\n",
       "4           1          1\n",
       "5           1          1\n",
       "6           1          1\n",
       "7           1          1\n",
       "8           1          1\n",
       "9           1          1\n",
       "10          1          1\n",
       "11          1          1\n",
       "12          1          1\n",
       "13          1          1\n",
       "14          1          1\n",
       "15          1          1\n",
       "16          1          1\n",
       "17          1          1\n",
       "18          1          1\n",
       "19          1          1\n",
       "20          1          1\n",
       "21          1          1\n",
       "22          1          1\n",
       "23          1          1\n",
       "24          1          1\n",
       "25          1          1\n",
       "26          1          1\n",
       "27          1          1\n",
       "28          1          1\n",
       "29          1          1\n",
       "...       ...        ...\n",
       "1274330     1          1\n",
       "1274331     1          1\n",
       "1274332     1          1\n",
       "1274333     1          1\n",
       "1274334     1          1\n",
       "1274335     1          1\n",
       "1274336     1          1\n",
       "1274337     1          1\n",
       "1274338     1          1\n",
       "1274339     1          1\n",
       "1274340     1          1\n",
       "1274341     1          1\n",
       "1274342     1          1\n",
       "1274343     1          1\n",
       "1274344     1          1\n",
       "1274345     1          1\n",
       "1274346     1          1\n",
       "1274347     1          1\n",
       "1274348     1          1\n",
       "1274349     1          1\n",
       "1274350     1          1\n",
       "1274351     1          1\n",
       "1274352     1          1\n",
       "1274353     1          1\n",
       "1274354     1          1\n",
       "1274355     1          1\n",
       "1274356     1          1\n",
       "1274357     1          1\n",
       "1274358     1          1\n",
       "1274359     1          1\n",
       "\n",
       "[1274360 rows x 2 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.groupby('Id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Subset Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-377-bf7e007e394c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_nodes\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df_edges = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges.csv\")\n",
    "df_nodes  = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes.csv\")\n",
    "\n",
    "edges = df_edges.values\n",
    "nodes = df_nodes.values\n",
    "\n",
    "#df_edges.columns.values\n",
    "#df_nodes.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [l.tolist() for l in list(edges)]\n",
    "nodes = [l.tolist() for l in list(nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [i[0] for i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_nodes = random.sample(nodes, 200)\n",
    "Sample_edges = list()\n",
    "\n",
    "for n1,n2 in edges:\n",
    "    if n1 in Sample_nodes and n2 in Sample_nodes:\n",
    "        \n",
    "        Sample_edges.append([n1,n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample_edges = random.sample(nodes, 200)\n",
    "#Sample_nodes = list()\n",
    "\n",
    "#Sample_edges_flattened = [val for sublist in Sample_edges for val in sublist]\n",
    "\n",
    "#for num, name, c in nodes:\n",
    "#    if num in Sample_edges_flattened:\n",
    "        \n",
    "#        Sample_nodes.append(num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)\n",
    "    \n",
    "    \n",
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in Sample_edges:\n",
    "    L_num.append((l[0],l[1]))\n",
    "    Source_num.append(l[0])\n",
    "    Target_num.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Sample_nodes,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_nodes.csv\", index = None, header=True)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_edges.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample with Biased Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_complete = nx.read_edgelist(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges_py.csv\",  nodetype=int, delimiter = \",\")\n",
    "#a_complete = nx.adjacency_matrix(g_complete)\n",
    "\n",
    "df_nodes  = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes_py.csv\", header = None)\n",
    "nodes = df_nodes.values\n",
    "nodes = [l.tolist() for l in list(nodes)]\n",
    "nodes_num = [i[0] for i in nodes]\n",
    "\n",
    "g.add_nodes_from(nodes_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274360\n",
      "4939240\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes_num))\n",
    "print(len(g_complete.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120649\n"
     ]
    }
   ],
   "source": [
    "node_attr_dict = dict()\n",
    "\n",
    "for num, name, c in nodes:\n",
    "    node_attr_dict[num] = c\n",
    "    \n",
    "print(node_attr_dict[0])\n",
    "    \n",
    "nx.set_node_attributes(g_complete, node_attr_dict, \"citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274360\n",
      "[107589, 1115655, 848931, 848932, 33910, 53000, 43667, 454, 1148682, 48812]\n"
     ]
    }
   ],
   "source": [
    "print(len(g_complete.nodes()))\n",
    "print(list(g_complete.nodes())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_max should be >= 621 --\n",
      "-- function get_graph takes 0.20066 secs --\n"
     ]
    }
   ],
   "source": [
    "sampleArgs = {\"sample\": \"biased_random_walk\", \"jump_bias\": \"random_walk_induced_graph_sampling\", \"n\": 1000, \"p\": 20.0, \"q\": 100.0, \"source_starts\": 2, \"source_returns\": 4, \"depth\": 2}\n",
    "\n",
    "##exact_n: forestfire, random_walk_induced_graph_sampling, random_walk_sampling_with_fly_back, adjacency, select\n",
    "##approx_n: snowball, bfs, walk, jump\n",
    "\n",
    "def get_graph(sampleArgs,g_complete,a_complete):\n",
    "    \n",
    "    if sampleArgs[\"sample\"] == \"biased_random_walk\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        #sampler = Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.biased_random_walk(sampleArgs[\"n\"], sampleArgs[\"p\"], sampleArgs[\"q\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"forestfire\":\n",
    "        sampler = ForestFire.ForestFire(g_complete,a_complete)\n",
    "        g = sampler.forestfire(sampleArgs[\"n\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"snowball\":\n",
    "        sampler = Snowball.Snowball(g_complete,a_complete)\n",
    "        g = sampler.snowball(sampleArgs[\"source_starts\"], sampleArgs[\"source_returns\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"random_walk_induced_graph_sampling\":\n",
    "        sampler = Random_Walk.Random_Walk(g_complete,a_complete)\n",
    "        g = sampler.random_walk_induced_graph_sampling(sampleArgs[\"n\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"random_walk_sampling_with_fly_back\":\n",
    "        sampler = Random_Walk.Random_Walk(g_complete,a_complete)\n",
    "        g = sampler.random_walk_sampling_with_fly_back(sampleArgs[\"n\"], sampleArgs[\"p\"])\n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"standard_bfs\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.standard_bfs(sampleArgs[\"source_starts\"], sampleArgs[\"depth\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"bfs\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.bfs(sampleArgs[\"n\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"walk\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.walk(sampleArgs[\"source_starts\"], sampleArgs[\"source_returns\"], sampleArgs[\"p\"])        \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"jump\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.jump(sampleArgs[\"source_starts\"], sampleArgs[\"p\"], sampleArgs[\"jump_bias\"])\n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"adjacency\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.adjacency(sampleArgs[\"n\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"select\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.adjacency(sampleArgs[\"n\"]) \n",
    "    \n",
    "    return g \n",
    "\n",
    "start_time = time.time()\n",
    "g = get_graph(sampleArgs, g_complete, a_complete)\n",
    "\n",
    "print(\"-- n_max should be >=\", len(g), \"--\")\n",
    "print(\"-- function get_graph takes %s secs --\" % round((time.time() - start_time),  5))\n",
    "\n",
    "if len(g) <= 200:\n",
    "    nx.draw(g, node_color = color_map, with_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n"
     ]
    }
   ],
   "source": [
    "Sample_nodes = list(g.nodes())\n",
    "Sample_edges = list(g.edges())\n",
    "\n",
    "print(len(Sample_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)\n",
    "    \n",
    "    \n",
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in Sample_edges:\n",
    "    L_num.append((l[0],l[1]))\n",
    "    Source_num.append(l[0])\n",
    "    Target_num.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Sample_nodes,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_nodes.csv\", index = None, header=True)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_edges.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09273370760313358"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nx.degree_assortativity_coefficient(g_complete, x='out', y='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274360 1274360\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "degrees = list(g_complete.degree())\n",
    "D = list()\n",
    "C = list()\n",
    "\n",
    "for num, degree in degrees:\n",
    "    c = A[num_author[num]]\n",
    "    \n",
    "    D.append(degree)\n",
    "    C.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4662064646170404, 0.0)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(D, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
