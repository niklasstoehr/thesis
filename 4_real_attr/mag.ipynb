{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Academic Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess MAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import pandas as pd \n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Network Processing\n",
    "\n",
    "## networkx\n",
    "import networkx as nx\n",
    "from networkx.generators import random_graphs\n",
    "from networkx.generators import social\n",
    "from networkx.generators import classic\n",
    "\n",
    "\n",
    "## smallworld\n",
    "from smallworld.draw import draw_network\n",
    "from smallworld import get_smallworld_graph\n",
    "\n",
    "## snap\n",
    "color_map =[\"grey\"]\n",
    "\n",
    "## graph sampling\n",
    "from sampling import ForestFire, Metropolis_Hastings, Random_Walk, Snowball, Ties, Base_Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/mag/mag_raw.txt','r') \n",
    "\n",
    "L = list()\n",
    "A = defaultdict(int) # default value of int is 0\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "n_list = list()\n",
    "\n",
    "while line:\n",
    "    \n",
    "    if \"#@\" in line:\n",
    "        n_list = line.replace(\"\\n\", \"\").split(\"#@\")[1].split(\",\")\n",
    "        \n",
    "        ## edges\n",
    "        if len(n_list) > 1: \n",
    "            for i in range(0, len(n_list)):\n",
    "                for j in range(i+1, len(n_list)):\n",
    "                        L.append((n_list[i], n_list[j]))                \n",
    "        else:\n",
    "            L.append((n_list[0], n_list[0]))\n",
    "            \n",
    "            \n",
    "                        \n",
    "    if \"#citation\" in line:\n",
    "        \n",
    "        c = line.split(\"#citation\")[1]\n",
    "        c = abs(int(c))\n",
    "        \n",
    "        for n in n_list:\n",
    "            A[n] +=  c\n",
    "                \n",
    "            #print(\"n\", n, \"c\", A[n], \"\\n\")\n",
    "    \n",
    "    line = f.readline() ## read next line\n",
    "\n",
    "f.close()\n",
    "\n",
    "## pre-process and sort\n",
    "L = set(L)\n",
    "\n",
    "A_sorted = sorted(A.items(), key=operator.itemgetter(1), reverse=True)\n",
    "A_sorted = [n_a[0] for n_a in A_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5366282\n",
      "['José A. Blakeley', 'Yuri Breitbart', 'Hector Garcia-Molina', 'Abraham Silberschatz', 'Tom C. Reyes', 'Stavros Christodoulakis', 'Leonidas Koveos', 'Umeshwar Dayal', 'Eric N. Hanson', 'Jennifer Widom', 'Angelika Kotz Dittrich', 'Klaus R. Dittrich', 'Meichun Hsu', 'Nathan Goodman', 'Gail E. Kaiser', 'William Kelley', 'Sunit K. Gala', 'Won Kim', 'Bruce Graham', 'Alfons Kemper', 'Guido Moerkotte', 'Injun Choi', 'Mark Scheevel', 'Jorge F. Garza', 'Vincent J. Kowalski', 'David Krieger', 'Tim Andrews', 'Teresa F. Lunt', 'Weiyi Meng', 'Clement T. Yu']\n",
      "38608\n",
      "Anil K. Jain\n",
      "1274360\n"
     ]
    }
   ],
   "source": [
    "print(len(L))\n",
    "print(list(A.keys())[:30])\n",
    "print(A[\"Leslie Lamport\"])\n",
    "print(A_sorted[2])\n",
    "print(len(A_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numberize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = list(range(0, len(A_sorted)))\n",
    "num_author = dict(zip(Num, A_sorted))\n",
    "author_num = dict(zip(A_sorted, Num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in L:\n",
    "    L_num.append((author_num[l[0]], author_num[l[1]]))\n",
    "    Source_num.append(author_num[l[0]])\n",
    "    Target_num.append(author_num[l[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Num:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Num:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Num,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes_py.csv\", index = None, header=False)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges_py.csv\", index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178387</td>\n",
       "      <td>178387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291530</td>\n",
       "      <td>291530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89476</td>\n",
       "      <td>89476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56353</td>\n",
       "      <td>56353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43112</td>\n",
       "      <td>43112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34639</td>\n",
       "      <td>34639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29704</td>\n",
       "      <td>29704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25352</td>\n",
       "      <td>25352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22391</td>\n",
       "      <td>22391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20071</td>\n",
       "      <td>20071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17710</td>\n",
       "      <td>17710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16276</td>\n",
       "      <td>16276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15067</td>\n",
       "      <td>15067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13724</td>\n",
       "      <td>13724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12592</td>\n",
       "      <td>12592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11418</td>\n",
       "      <td>11418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10763</td>\n",
       "      <td>10763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9981</td>\n",
       "      <td>9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9495</td>\n",
       "      <td>9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8832</td>\n",
       "      <td>8832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8324</td>\n",
       "      <td>8324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7779</td>\n",
       "      <td>7779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7436</td>\n",
       "      <td>7436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7057</td>\n",
       "      <td>7057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6822</td>\n",
       "      <td>6822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6366</td>\n",
       "      <td>6366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6070</td>\n",
       "      <td>6070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5796</td>\n",
       "      <td>5796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5487</td>\n",
       "      <td>5487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5215</td>\n",
       "      <td>5215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47148</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47225</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47910</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49253</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50079</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50828</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50894</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51253</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51318</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51896</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52759</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53355</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53837</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54748</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55173</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55554</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56327</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60358</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63216</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64488</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65038</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66236</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67916</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68104</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70802</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72316</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79494</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88285</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120649</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6870 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id    name\n",
       "citations                \n",
       "0          178387  178387\n",
       "1          291530  291530\n",
       "2           89476   89476\n",
       "3           56353   56353\n",
       "4           43112   43112\n",
       "5           34639   34639\n",
       "6           29704   29704\n",
       "7           25352   25352\n",
       "8           22391   22391\n",
       "9           20071   20071\n",
       "10          17710   17710\n",
       "11          16276   16276\n",
       "12          15067   15067\n",
       "13          13724   13724\n",
       "14          12592   12592\n",
       "15          11418   11418\n",
       "16          10763   10763\n",
       "17           9981    9981\n",
       "18           9495    9495\n",
       "19           8832    8832\n",
       "20           8324    8324\n",
       "21           7779    7779\n",
       "22           7436    7436\n",
       "23           7057    7057\n",
       "24           6822    6822\n",
       "25           6366    6366\n",
       "26           6070    6070\n",
       "27           5796    5796\n",
       "28           5487    5487\n",
       "29           5215    5215\n",
       "...           ...     ...\n",
       "47148           1       1\n",
       "47225           1       1\n",
       "47910           1       1\n",
       "49153           1       1\n",
       "49253           1       1\n",
       "50079           1       1\n",
       "50828           1       1\n",
       "50894           1       1\n",
       "51253           1       1\n",
       "51318           1       1\n",
       "51896           1       1\n",
       "52759           1       1\n",
       "53355           1       1\n",
       "53837           1       1\n",
       "54748           1       1\n",
       "55173           1       1\n",
       "55554           1       1\n",
       "56327           1       1\n",
       "60358           1       1\n",
       "63216           1       1\n",
       "64488           1       1\n",
       "65038           1       1\n",
       "66236           1       1\n",
       "67916           1       1\n",
       "68104           1       1\n",
       "70802           1       1\n",
       "72316           1       1\n",
       "79494           1       1\n",
       "88285           1       1\n",
       "120649          1       1\n",
       "\n",
       "[6870 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.groupby('citations').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Subset Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges.csv\")\n",
    "df_nodes  = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes.csv\")\n",
    "\n",
    "edges = df_edges.values\n",
    "nodes = df_nodes.values\n",
    "\n",
    "#df_edges.columns.values\n",
    "#df_nodes.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [l.tolist() for l in list(edges)]\n",
    "nodes = [l.tolist() for l in list(nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [i[0] for i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-420-931f9a47c744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mn1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSample_nodes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSample_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mSample_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Sample_nodes = random.sample(nodes, 200)\n",
    "Sample_edges = list()\n",
    "\n",
    "for n1,n2 in edges:\n",
    "    if n1 in Sample_nodes and n2 in Sample_nodes:\n",
    "        \n",
    "        Sample_edges.append([n1,n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample_edges = random.sample(nodes, 200)\n",
    "#Sample_nodes = list()\n",
    "\n",
    "#Sample_edges_flattened = [val for sublist in Sample_edges for val in sublist]\n",
    "\n",
    "#for num, name, c in nodes:\n",
    "#    if num in Sample_edges_flattened:\n",
    "        \n",
    "#        Sample_nodes.append(num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)\n",
    "    \n",
    "    \n",
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in Sample_edges:\n",
    "    L_num.append((l[0],l[1]))\n",
    "    Source_num.append(l[0])\n",
    "    Target_num.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-415-2198bd050897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     {'Id': Sample_nodes,\n\u001b[1;32m      3\u001b[0m      \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNames_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m      \u001b[0;34m'citations'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mC_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     })\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7313\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7315\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7317\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7359\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Sample_nodes,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_nodes.csv\", index = None, header=True)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_edges.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample with Biased Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_complete = nx.read_edgelist(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges_py.csv\",  nodetype=int, delimiter = \",\")\n",
    "#a_complete = nx.adjacency_matrix(g_complete)\n",
    "\n",
    "df_nodes  = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes_py.csv\", header = None)\n",
    "nodes = df_nodes.values\n",
    "nodes = [l.tolist() for l in list(nodes)]\n",
    "nodes_num = [i[0] for i in nodes]\n",
    "\n",
    "g.add_nodes_from(nodes_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274360\n",
      "4939240\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes_num))\n",
    "print(len(g_complete.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120649\n"
     ]
    }
   ],
   "source": [
    "node_attr_dict = dict()\n",
    "\n",
    "for num, name, c in nodes:\n",
    "    node_attr_dict[num] = c\n",
    "    \n",
    "print(node_attr_dict[0])\n",
    "    \n",
    "nx.set_node_attributes(g_complete, node_attr_dict, \"citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274360\n",
      "[107589, 1115655, 848931, 848932, 33910, 53000, 43667, 454, 1148682, 48812]\n"
     ]
    }
   ],
   "source": [
    "print(len(g_complete.nodes()))\n",
    "print(list(g_complete.nodes())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_max should be >= 597 --\n",
      "-- function get_graph takes 0.2005 secs --\n"
     ]
    }
   ],
   "source": [
    "sampleArgs = {\"sample\": \"biased_random_walk\", \"jump_bias\": \"random_walk_induced_graph_sampling\", \"n\": 1000, \"p\": 20.0, \"q\": 100.0, \"source_starts\": 2, \"source_returns\": 4, \"depth\": 2}\n",
    "\n",
    "##exact_n: forestfire, random_walk_induced_graph_sampling, random_walk_sampling_with_fly_back, adjacency, select\n",
    "##approx_n: snowball, bfs, walk, jump\n",
    "\n",
    "def get_graph(sampleArgs,g_complete,a_complete):\n",
    "    \n",
    "    if sampleArgs[\"sample\"] == \"biased_random_walk\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        #sampler = Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.biased_random_walk(sampleArgs[\"n\"], sampleArgs[\"p\"], sampleArgs[\"q\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"forestfire\":\n",
    "        sampler = ForestFire.ForestFire(g_complete,a_complete)\n",
    "        g = sampler.forestfire(sampleArgs[\"n\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"snowball\":\n",
    "        sampler = Snowball.Snowball(g_complete,a_complete)\n",
    "        g = sampler.snowball(sampleArgs[\"source_starts\"], sampleArgs[\"source_returns\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"random_walk_induced_graph_sampling\":\n",
    "        sampler = Random_Walk.Random_Walk(g_complete,a_complete)\n",
    "        g = sampler.random_walk_induced_graph_sampling(sampleArgs[\"n\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"random_walk_sampling_with_fly_back\":\n",
    "        sampler = Random_Walk.Random_Walk(g_complete,a_complete)\n",
    "        g = sampler.random_walk_sampling_with_fly_back(sampleArgs[\"n\"], sampleArgs[\"p\"])\n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"standard_bfs\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.standard_bfs(sampleArgs[\"source_starts\"], sampleArgs[\"depth\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"bfs\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.bfs(sampleArgs[\"n\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"walk\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.walk(sampleArgs[\"source_starts\"], sampleArgs[\"source_returns\"], sampleArgs[\"p\"])        \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"jump\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.jump(sampleArgs[\"source_starts\"], sampleArgs[\"p\"], sampleArgs[\"jump_bias\"])\n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"adjacency\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.adjacency(sampleArgs[\"n\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"select\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.adjacency(sampleArgs[\"n\"]) \n",
    "    \n",
    "    return g \n",
    "\n",
    "start_time = time.time()\n",
    "g = get_graph(sampleArgs, g_complete, a_complete)\n",
    "\n",
    "print(\"-- n_max should be >=\", len(g), \"--\")\n",
    "print(\"-- function get_graph takes %s secs --\" % round((time.time() - start_time),  5))\n",
    "\n",
    "if len(g) <= 200:\n",
    "    nx.draw(g, node_color = color_map, with_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016\n"
     ]
    }
   ],
   "source": [
    "Sample_nodes = list(g.nodes())\n",
    "Sample_edges = list(g.edges())\n",
    "\n",
    "print(len(Sample_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)\n",
    "    \n",
    "    \n",
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in Sample_edges:\n",
    "    L_num.append((l[0],l[1]))\n",
    "    Source_num.append(l[0])\n",
    "    Target_num.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Sample_nodes,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_nodes.csv\", index = None, header=True)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_edges.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09273370760313358"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nx.degree_assortativity_coefficient(g_complete, x='out', y='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274360 1274360\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "degrees = list(g_complete.degree())\n",
    "D = list()\n",
    "C = list()\n",
    "\n",
    "for num, degree in degrees:\n",
    "    c = A[num_author[num]]\n",
    "    \n",
    "    D.append(degree)\n",
    "    C.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4662064646170404, 0.0)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(D, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
