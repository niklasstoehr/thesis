{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process and Load Microsoft Academic Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess MAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import pandas as pd \n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Network Processing\n",
    "\n",
    "## networkx\n",
    "import networkx as nx\n",
    "from networkx.generators import random_graphs\n",
    "from networkx.generators import social\n",
    "from networkx.generators import classic\n",
    "\n",
    "\n",
    "## smallworld\n",
    "from smallworld.draw import draw_network\n",
    "from smallworld import get_smallworld_graph\n",
    "\n",
    "## snap\n",
    "color_map =[\"grey\"]\n",
    "\n",
    "## graph sampling\n",
    "from sampling import ForestFire, Metropolis_Hastings, Random_Walk, Snowball, Ties, Base_Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/mag/mag_raw.txt','r') \n",
    "\n",
    "L = list()\n",
    "A = defaultdict(int) # default value of int is 0\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "n_list = list()\n",
    "\n",
    "while line:\n",
    "    \n",
    "    if \"#@\" in line:\n",
    "        n_list = line.replace(\"\\n\", \"\").split(\"#@\")[1].split(\",\")\n",
    "        \n",
    "        ## edges\n",
    "        if len(n_list) > 1: \n",
    "            for i in range(0, len(n_list)):\n",
    "                for j in range(i+1, len(n_list)):\n",
    "                        L.append((n_list[i], n_list[j]))                \n",
    "        else:\n",
    "            L.append((n_list[0], n_list[0]))\n",
    "            \n",
    "            \n",
    "                        \n",
    "    if \"#citation\" in line:\n",
    "        \n",
    "        c = line.split(\"#citation\")[1]\n",
    "        c = abs(int(c))\n",
    "        \n",
    "        for n in n_list:\n",
    "            A[n] +=  c\n",
    "                \n",
    "            #print(\"n\", n, \"c\", A[n], \"\\n\")\n",
    "    \n",
    "    line = f.readline() ## read next line\n",
    "\n",
    "f.close()\n",
    "\n",
    "## pre-process and sort\n",
    "L = set(L)\n",
    "\n",
    "A_sorted = sorted(A.items(), key=operator.itemgetter(1), reverse=True)\n",
    "A_sorted = [n_a[0] for n_a in A_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(L))\n",
    "print(list(A.keys())[:30])\n",
    "print(A[\"Leslie Lamport\"])\n",
    "print(A_sorted[2])\n",
    "print(len(A_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numberize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = list(range(0, len(A_sorted)))\n",
    "num_author = dict(zip(Num, A_sorted))\n",
    "author_num = dict(zip(A_sorted, Num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in L:\n",
    "    L_num.append((author_num[l[0]], author_num[l[1]]))\n",
    "    Source_num.append(author_num[l[0]])\n",
    "    Target_num.append(author_num[l[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Num:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Num:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Num,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes_py.csv\", index = None, header=False)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges_py.csv\", index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.groupby('citations').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Subset Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges.csv\")\n",
    "df_nodes  = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes.csv\")\n",
    "\n",
    "edges = df_edges.values\n",
    "nodes = df_nodes.values\n",
    "\n",
    "#df_edges.columns.values\n",
    "#df_nodes.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [l.tolist() for l in list(edges)]\n",
    "nodes = [l.tolist() for l in list(nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [i[0] for i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_nodes = random.sample(nodes, 200)\n",
    "Sample_edges = list()\n",
    "\n",
    "for n1,n2 in edges:\n",
    "    if n1 in Sample_nodes and n2 in Sample_nodes:\n",
    "        \n",
    "        Sample_edges.append([n1,n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample_edges = random.sample(nodes, 200)\n",
    "#Sample_nodes = list()\n",
    "\n",
    "#Sample_edges_flattened = [val for sublist in Sample_edges for val in sublist]\n",
    "\n",
    "#for num, name, c in nodes:\n",
    "#    if num in Sample_edges_flattened:\n",
    "        \n",
    "#        Sample_nodes.append(num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)\n",
    "    \n",
    "    \n",
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in Sample_edges:\n",
    "    L_num.append((l[0],l[1]))\n",
    "    Source_num.append(l[0])\n",
    "    Target_num.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Sample_nodes,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_nodes.csv\", index = None, header=True)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_edges.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample with Biased Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_complete = nx.read_edgelist(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/edges_py.csv\",  nodetype=int, delimiter = \",\")\n",
    "#a_complete = nx.adjacency_matrix(g_complete)\n",
    "\n",
    "df_nodes  = pd.read_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/nodes_py.csv\", header = None)\n",
    "nodes = df_nodes.values\n",
    "nodes = [l.tolist() for l in list(nodes)]\n",
    "nodes_num = [i[0] for i in nodes]\n",
    "\n",
    "g.add_nodes_from(nodes_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nodes_num))\n",
    "print(len(g_complete.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_attr_dict = dict()\n",
    "\n",
    "for num, name, c in nodes:\n",
    "    node_attr_dict[num] = c\n",
    "    \n",
    "print(node_attr_dict[0])\n",
    "    \n",
    "nx.set_node_attributes(g_complete, node_attr_dict, \"citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(g_complete.nodes()))\n",
    "print(list(g_complete.nodes())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "sampleArgs = {\"sample\": \"biased_random_walk\", \"jump_bias\": \"random_walk_induced_graph_sampling\", \"n\": 1000, \"p\": 20.0, \"q\": 100.0, \"source_starts\": 2, \"source_returns\": 4, \"depth\": 2}\n",
    "\n",
    "##exact_n: forestfire, random_walk_induced_graph_sampling, random_walk_sampling_with_fly_back, adjacency, select\n",
    "##approx_n: snowball, bfs, walk, jump\n",
    "\n",
    "def get_graph(sampleArgs,g_complete,a_complete):\n",
    "    \n",
    "    if sampleArgs[\"sample\"] == \"biased_random_walk\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        #sampler = Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.biased_random_walk(sampleArgs[\"n\"], sampleArgs[\"p\"], sampleArgs[\"q\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"forestfire\":\n",
    "        sampler = ForestFire.ForestFire(g_complete,a_complete)\n",
    "        g = sampler.forestfire(sampleArgs[\"n\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"snowball\":\n",
    "        sampler = Snowball.Snowball(g_complete,a_complete)\n",
    "        g = sampler.snowball(sampleArgs[\"source_starts\"], sampleArgs[\"source_returns\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"random_walk_induced_graph_sampling\":\n",
    "        sampler = Random_Walk.Random_Walk(g_complete,a_complete)\n",
    "        g = sampler.random_walk_induced_graph_sampling(sampleArgs[\"n\"])\n",
    "\n",
    "    if sampleArgs[\"sample\"] == \"random_walk_sampling_with_fly_back\":\n",
    "        sampler = Random_Walk.Random_Walk(g_complete,a_complete)\n",
    "        g = sampler.random_walk_sampling_with_fly_back(sampleArgs[\"n\"], sampleArgs[\"p\"])\n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"standard_bfs\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.standard_bfs(sampleArgs[\"source_starts\"], sampleArgs[\"depth\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"bfs\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.bfs(sampleArgs[\"n\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"walk\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.walk(sampleArgs[\"source_starts\"], sampleArgs[\"source_returns\"], sampleArgs[\"p\"])        \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"jump\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.jump(sampleArgs[\"source_starts\"], sampleArgs[\"p\"], sampleArgs[\"jump_bias\"])\n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"adjacency\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.adjacency(sampleArgs[\"n\"]) \n",
    "        \n",
    "    if sampleArgs[\"sample\"] == \"select\":\n",
    "        sampler = Base_Samplers.Base_Samplers(g_complete,a_complete)\n",
    "        g = sampler.adjacency(sampleArgs[\"n\"]) \n",
    "    \n",
    "    return g \n",
    "\n",
    "start_time = time.time()\n",
    "g = get_graph(sampleArgs, g_complete, a_complete)\n",
    "\n",
    "print(\"-- n_max should be >=\", len(g), \"--\")\n",
    "print(\"-- function get_graph takes %s secs --\" % round((time.time() - start_time),  5))\n",
    "\n",
    "if len(g) <= 200:\n",
    "    nx.draw(g, node_color = color_map, with_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_nodes = list(g.nodes())\n",
    "Sample_edges = list(g.edges())\n",
    "\n",
    "print(len(Sample_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Citations\n",
    "C_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    c = A[num_author[num]]\n",
    "    C_num.append(c)\n",
    "    \n",
    "## Names\n",
    "Names_num = list()\n",
    "\n",
    "for num in Sample_nodes:\n",
    "    name = num_author[num]\n",
    "    Names_num.append(name)\n",
    "    \n",
    "    \n",
    "## Links\n",
    "L_num = list()\n",
    "Source_num = list()\n",
    "Target_num = list()\n",
    "\n",
    "for l in Sample_edges:\n",
    "    L_num.append((l[0],l[1]))\n",
    "    Source_num.append(l[0])\n",
    "    Target_num.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(\n",
    "    {'Id': Sample_nodes,\n",
    "     'name': Names_num,\n",
    "     'citations': C_num,\n",
    "    })\n",
    "\n",
    "edges = pd.DataFrame(\n",
    "    {'Source': Source_num,\n",
    "     'Target': Target_num,\n",
    "    })\n",
    "\n",
    "nodes.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_nodes.csv\", index = None, header=True)\n",
    "edges.to_csv(\"/Users/niklasstoehr/Programming/thesis/4_real_attr/data/mag/sample_edges.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.degree_assortativity_coefficient(g_complete, x='out', y='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "degrees = list(g_complete.degree())\n",
    "D = list()\n",
    "C = list()\n",
    "\n",
    "for num, degree in degrees:\n",
    "    c = A[num_author[num]]\n",
    "    \n",
    "    D.append(degree)\n",
    "    C.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(D, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
