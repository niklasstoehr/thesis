{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Binary Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Basic\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# Computation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import scipy\n",
    "from scipy.stats.stats import pearsonr \n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Network Processing\n",
    "import networkx as nx\n",
    "from networkx.generators import classic\n",
    "\n",
    "## node colour\n",
    "color_map = [\"steelblue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## supporting functions\n",
    "from support.preprocessing import sort_adjacency, reshape_A, calculate_A_shape, reconstruct_adjacency, pad_matrix, unpad_matrix, prepare_in_out\n",
    "from support.metrics import compute_mig, compute_mi\n",
    "from support.graph_generating import generate_single, generate_manifold, generate_topol_manifold, generate_topol_manifold\n",
    "from support.param_generating import generate_param_graph_manifold, generate_param_topol_manifold\n",
    "from support.latent_space import vis2D, visDistr\n",
    "\n",
    "## import model\n",
    "from models.VAE import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Network Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_graph(b,h,draw): \n",
    "\n",
    "    g = classic.balanced_tree(b, h)\n",
    "\n",
    "    if draw:\n",
    "        nx.draw(g, node_color = color_map, with_labels = True)\n",
    "        plt.show()\n",
    "    \n",
    "    return g\n",
    "\n",
    "g = get_graph(b = 2, h = 4, draw = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generate_data(dataArgs): \n",
    "    \n",
    "    ## Data ________________________________\n",
    "\n",
    "    G = np.zeros((dataArgs[\"n_graphs\"], *calculate_A_shape(dataArgs[\"n_max\"], diag_offset = dataArgs[\"diag_offset\"])))\n",
    "\n",
    "    ## Ground Truth Labels ______________________________\n",
    "\n",
    "    T = list()\n",
    "    T_array = np.zeros((dataArgs[\"n_graphs\"],2))\n",
    "\n",
    "    ## Generate Graph Data_______________________________\n",
    "\n",
    "    for i in tqdm(range(0,dataArgs[\"n_graphs\"])):\n",
    "\n",
    "        ## Generate Graph Type ______________________________________________\n",
    "\n",
    "        if dataArgs[\"fix_n\"] == True:\n",
    "            h = dataArgs[\"h\"]         # generate fixed number of nodes n_max\n",
    "        else:\n",
    "            h = random.randint(0, dataArgs[\"h\"]) # generate number of nodes n between 1 and n_max and\n",
    "\n",
    "        b = random.randint(dataArgs[\"b\"][0], dataArgs[\"b\"][1]) \n",
    "        \n",
    "        g = get_graph(b, h, draw = False)\n",
    "        \n",
    "        g, a = sort_adjacency(g)\n",
    "        a = pad_matrix(a, dataArgs[\"n_max\"], dataArgs[\"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "        a_transformed = reshape_A(a, diag_offset = dataArgs[\"diag_offset\"])\n",
    "\n",
    "\n",
    "        ## Build Data Arrays___________________________________________________\n",
    "\n",
    "        G[i] = a_transformed\n",
    "\n",
    "        t = dict()\n",
    "        t[\"b\"] = b\n",
    "        t[\"h\"] = h\n",
    "\n",
    "        T_array[i] = [b,h]\n",
    "        T.append(t)\n",
    "\n",
    "\n",
    "\n",
    "    ## Input and Output Size ___________________________________________________________\n",
    "\n",
    "    T, input_shape, output_shape = prepare_in_out(T, dataArgs[\"diag_offset\"], calculate_A_shape(dataArgs[\"n_max\"], dataArgs[\"diag_offset\"]))\n",
    "    print(\"input_shape:\", input_shape, \", output_shape:\", output_shape)\n",
    "    \n",
    "    ## scale parameters in T_array for smoother training\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(T_array)\n",
    "    T_array = scaler.transform(T_array)\n",
    "    \n",
    "    return G,T,T_array,input_shape,output_shape,scaler\n",
    "    \n",
    "# n formula = b*(b**h) - 1\n",
    "dataArgs = {\"n_graphs\": 1000, \"n_max\": 32, \"h\": 4, \"b\": [1,2], \"fix_n\": False, \"diag_offset\": -1, \"diag_value\": 1, \"clip\": True}  #\"diag_offset\" - 1 == full adjacency\n",
    "G, T, T_array, input_shape, output_shape,scaler = generate_data(dataArgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beta-VAE (MLP, 2D_Conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "modelArgs = {\"nn_architecture\": \"2D_conv\", \"param_loss\": False, \"latent_dim\": 2, \"growth_param\": T_array.shape[1], \"filters\": 16, \"kernel_size\": 3, \"input_shape\": input_shape, \"output_shape\": output_shape}\n",
    "trainArgs = {\"beta\": 200, \"loss\": \"binary_crossentropy\", \"weights\": \"train\", \"early_stop\": 1, \"batch_size\": 256, \"epochs\": 1, \"data_split\": 0.2}\n",
    "\n",
    "vae = VAE(modelArgs, trainArgs, G, T_array)\n",
    "\n",
    "models = vae.model \n",
    "data = vae.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through single data dimension and oberseve single latent space dimension  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     48
    ]
   },
   "outputs": [],
   "source": [
    "def latent_space_feature_correlation(analyzeArgs, modelArgs, dataArgs, models,batch_size=128,model_name=\"vae_graph\"):\n",
    "\n",
    "    if modelArgs[\"param_loss\"]:\n",
    "        encoder, graph_decoder, param_decoder = models  # trained models\n",
    "    else:\n",
    "        encoder, graph_decoder = models  # trained models\n",
    "    \n",
    "    \n",
    "    \n",
    "    if analyzeArgs[\"root_params\"] == 1 or modelArgs[\"latent_dim\"] == 1:\n",
    "        \n",
    "        ## Generate Graph Data_______________________________\n",
    "        \n",
    "        b = dataArgs[\"b\"][1]\n",
    "        H = np.linspace(0, dataArgs[\"h\"]+1, analyzeArgs[\"n_config_graphs\"], dtype = int)  # array 0.1, 0.2 - 1 / n_config_graphs  \n",
    "        \n",
    "        ## growth and topol parameters\n",
    "        growth_topol_params = [\"h\",\"density\", \"diameter\", \"cluster_coef\", \"assort\", \"#edges\", \"avg_degree\"]\n",
    "        \n",
    "        ## store graphs and targets\n",
    "        # shape: n_config_graphs, params, upper_A_size\n",
    "        G = np.zeros((analyzeArgs[\"n_config_graphs\"], *calculate_A_shape(dataArgs[\"n_max\"], dataArgs[\"diag_offset\"])))\n",
    "        Growth_Topol = np.zeros((analyzeArgs[\"n_config_graphs\"], len(growth_topol_params)))\n",
    "    \n",
    "        for i, h in enumerate(H):\n",
    "\n",
    "            ## Generate Graph Type ______________________________________________\n",
    "\n",
    "            g = get_graph(int(b), int(h), draw = False)\n",
    "\n",
    "            g, a = sort_adjacency(g)\n",
    "            a = pad_matrix(a, dataArgs[\"n_max\"], dataArgs[\"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "            upper_a = reshape_A(a, dataArgs[\"diag_offset\"])\n",
    "\n",
    "\n",
    "            ## Generate Ground Truth features____________________________________\n",
    "\n",
    "            density = nx.density(g)\n",
    "\n",
    "            if nx.is_connected(g):\n",
    "                diameter = nx.diameter(g)\n",
    "            else:\n",
    "                diameter = -1\n",
    "\n",
    "            cluster_coef = nx.average_clustering(g)\n",
    "\n",
    "            if g.number_of_edges() > 0:\n",
    "                assort = nx.degree_assortativity_coefficient(g, x='out', y='in')\n",
    "            else:\n",
    "                assort = 0\n",
    "\n",
    "            edges = g.number_of_edges()\n",
    "\n",
    "            avg_degree = sum(i for i in nx.degree_centrality(g).values()) / len(nx.degree_centrality(g).keys())\n",
    "\n",
    "\n",
    "            ## toDO: add more graph topologies\n",
    "\n",
    "            ## Build Data Arrays___________________________________________________\n",
    "\n",
    "            G[i] = upper_a\n",
    "\n",
    "            Growth_Topol[i,0] = h\n",
    "            Growth_Topol[i,1] = density\n",
    "            Growth_Topol[i,2] = diameter\n",
    "            Growth_Topol[i,3] = cluster_coef\n",
    "            Growth_Topol[i,4] = assort\n",
    "            Growth_Topol[i,5] = edges\n",
    "            Growth_Topol[i,6] = avg_degree\n",
    "\n",
    "  \n",
    "    \n",
    "        ## ENCODER - 2D Digit Classes ______________________________________________\n",
    "\n",
    "        # display a 2D plot of the digit classes in the latent space\n",
    "        z_mean, _, _ = encoder.predict(G, batch_size = batch_size)\n",
    "        \n",
    "        \n",
    "        ## Measure the Mutual Information Gap ____________________________________________\n",
    "        if analyzeArgs[\"metric\"] == \"mig\":\n",
    "            mig = compute_mig(H, np.squeeze(z_mean))\n",
    "            \n",
    "        \n",
    "        ## Visualize Latent Variables x Graph Properties ____________________________\n",
    "        fig, ax = plt.subplots(nrows= z_mean.shape[1], ncols= Growth_Topol.shape[1], figsize=(20, 10))\n",
    "\n",
    "        for latent_z, row in enumerate(ax):  \n",
    "            \n",
    "            if z_mean.shape[1] == 1:   # only one latent variable\n",
    "                \n",
    "                if latent_z == 0:\n",
    "                    y = z_mean[:,0]\n",
    "                    x = Growth_Topol[:,latent_z]\n",
    "                    row.plot(x, y) \n",
    "\n",
    "                else:\n",
    "                    y = z_mean[:,0]\n",
    "                    x = Growth_Topol[:,latent_z]\n",
    "                    #row.scatter(x, y) \n",
    "                    sns.regplot(x, y, color=\"steelblue\", ax=row)\n",
    "\n",
    "                    ## plot trend line\n",
    "                    #x = np.nan_to_num(x)\n",
    "                    #y = np.nan_to_num(y)\n",
    "\n",
    "                    #z = np.polyfit(x, y, 1)\n",
    "                    #p = np.poly1d(z)\n",
    "                    #row.plot(x,p(x),\"steelblue\")\n",
    "                    \n",
    "                ## compute correlation and standardized covariance\n",
    "                corr = round(pearsonr(x,y)[0],3)\n",
    "                cov = round(np.cov(x, y)[0][1]/max(x),3)\n",
    "                row.annotate(\"corr:\"+str(corr)+\", cov:\"+str(cov), xy=(0, 1), xytext=(12, -12), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "                    \n",
    "            else:                     # multiple latent variables\n",
    "                \n",
    "                for feature, col in enumerate(row):\n",
    "\n",
    "                    if feature == 0:\n",
    "                        y = z_mean[:,latent_z]\n",
    "                        x = Growth_Topol[:,feature]\n",
    "                        col.plot(x, y) \n",
    "\n",
    "                    else:\n",
    "                        y = z_mean[:,latent_z]\n",
    "                        x = Growth_Topol[:,feature]\n",
    "                        #col.scatter(x, y) \n",
    "                        sns.regplot(x, y, color=\"steelblue\", ax=col)\n",
    "\n",
    "                        ## plot trend line\n",
    "                        #x = np.nan_to_num(x)\n",
    "                        #y = np.nan_to_num(y)\n",
    "\n",
    "                        #z = np.polyfit(x, y, 1)\n",
    "                        #p = np.poly1d(z)\n",
    "                        #col.plot(x,p(x),\"steelblue\")\n",
    "            \n",
    "                \n",
    "                    ## compute correlation and standardized covariance\n",
    "                    corr = round(pearsonr(x,y)[0],3)\n",
    "                    cov = round(np.cov(x, y)[0][1]/max(x),3)\n",
    "                    col.annotate(\"corr:\"+str(corr)+\", cov:\"+str(cov), xy=(0, 1), xytext=(12, -12), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "\n",
    "\n",
    "        ## add row and column titles _____________________\n",
    "        \n",
    "        if z_mean.shape[1] == 1:   # only one latent variable\n",
    "                \n",
    "            cols = [t for t in growth_topol_params]\n",
    "            \n",
    "            for axis, col in zip(ax[:,], cols):\n",
    "                axis.set_title(col, fontweight='bold')\n",
    "                \n",
    "        \n",
    "        if z_mean.shape[1] != 1:   # more than one latent variable\n",
    "            \n",
    "            rows = ['z_{}'.format(row) for row in range(z_mean.shape[-1])]\n",
    "            cols = [t for t in growth_topol_params]\n",
    "\n",
    "            for axis, row in zip(ax[:,0], rows):\n",
    "                axis.set_ylabel(row, rotation=0, size='large', fontweight='bold')\n",
    "            \n",
    "            for axis, col in zip(ax[0], cols):\n",
    "                axis.set_title(col, fontweight='bold')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    if analyzeArgs[\"root_params\"] == 2 and modelArgs[\"latent_dim\"] != 1:\n",
    "        \n",
    "        ## Generate Graph Data_______________________________\n",
    "        B = np.linspace(dataArgs[\"b\"][0],dataArgs[\"b\"][1], analyzeArgs[\"n_config_graphs\"], dtype = int)\n",
    "        H = np.linspace(0,dataArgs[\"h\"], analyzeArgs[\"n_config_graphs\"], dtype = int)  # array 0.1, 0.2 - 1 / n_config_graphs  \n",
    "        \n",
    "        ## growth and topol parameters\n",
    "        growth_params = [\"b\", \"h\"]\n",
    "        topol_params = [\"density\", \"diameter\", \"cluster_coef\", \"assort\", \"#edges\", \"avg_degree\"]\n",
    "\n",
    "        ## store graphs and targets\n",
    "        # shape: n_config_graphs, params, upper_A_size\n",
    "        G = np.zeros((analyzeArgs[\"n_config_graphs\"]**len(growth_params), *calculate_A_shape(dataArgs[\"n_max\"], dataArgs[\"diag_offset\"])))\n",
    "        Growth = np.zeros((analyzeArgs[\"n_config_graphs\"]**len(growth_params), len(growth_params)))\n",
    "        Topol = np.zeros((analyzeArgs[\"n_config_graphs\"]**len(growth_params), len(topol_params)))\n",
    "\n",
    "        ## iterate through topological features\n",
    "        graph_configs = np.asarray(list(itertools.product(B,H)))\n",
    "        \n",
    "\n",
    "        for i, (b,h) in enumerate(graph_configs):\n",
    "\n",
    "            ## Generate Graph Type ______________________________________________\n",
    "\n",
    "            g = get_graph(int(b), int(h), draw = False)\n",
    "\n",
    "            g, a = sort_adjacency(g)\n",
    "            a = pad_matrix(a, dataArgs[\"n_max\"], dataArgs[\"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "            upper_a = reshape_A(a, dataArgs[\"diag_offset\"])\n",
    "\n",
    "\n",
    "            ## Generate Ground Truth features____________________________________\n",
    "\n",
    "            density = nx.density(g)\n",
    "\n",
    "            if nx.is_connected(g):\n",
    "                diameter = nx.diameter(g)\n",
    "            else:\n",
    "                diameter = -1\n",
    "\n",
    "            cluster_coef = nx.average_clustering(g)\n",
    "\n",
    "            if g.number_of_edges() > 0:\n",
    "                assort = nx.degree_assortativity_coefficient(g, x='out', y='in')\n",
    "            else:\n",
    "                assort = 0\n",
    "\n",
    "            edges = g.number_of_edges()\n",
    "\n",
    "            avg_degree = sum(i for i in nx.degree_centrality(g).values()) / len(nx.degree_centrality(g).keys())\n",
    "\n",
    "\n",
    "            ## toDO: add more graph topologies\n",
    "\n",
    "            ## Build Data Arrays___________________________________________________\n",
    "\n",
    "            G[i] = upper_a\n",
    "\n",
    "            Growth[i,0] = int(b)\n",
    "            Growth[i,1] = int(h)\n",
    "\n",
    "            Topol[i,0] = density\n",
    "            Topol[i,1] = diameter\n",
    "            Topol[i,2] = cluster_coef\n",
    "            Topol[i,3] = assort\n",
    "            Topol[i,4] = edges\n",
    "            Topol[i,5] = avg_degree\n",
    "  \n",
    "    \n",
    "        ## ENCODER - 2D Digit Classes ______________________________________________\n",
    "\n",
    "        # display a 2D plot of the digit classes in the latent space\n",
    "        z_mean, _, _ = encoder.predict(G, batch_size = batch_size)\n",
    "        \n",
    "                \n",
    "        ## Measure the Mutual Information Gap ____________________________________________\n",
    "        if analyzeArgs[\"metric\"] == \"mig\":\n",
    "            #mi = compute_mi(P, np.squeeze(z_mean))\n",
    "            mig = compute_mig(Growth, z_mean)\n",
    "        \n",
    "        \n",
    "        ##  Reshape Array according to Parameters  \n",
    "        z_mean_growth = np.reshape(z_mean, (analyzeArgs[\"n_config_graphs\"], analyzeArgs[\"n_config_graphs\"], -1))\n",
    "        Growth = np.reshape(Growth,(analyzeArgs[\"n_config_graphs\"], analyzeArgs[\"n_config_graphs\"], -1))\n",
    "            \n",
    "        ## 1.) Growth Parameters________________________________________________________\n",
    "\n",
    "        ## Visualize Latent Variables x Growth Parameters ____________________________\n",
    "\n",
    "        fig, ax = plt.subplots(nrows= z_mean_growth.shape[-1] , ncols= len(growth_params))\n",
    "\n",
    "        for latent_z, row in enumerate(ax):        \n",
    "            for feature, col in enumerate(row):\n",
    "\n",
    "                if feature == 0:\n",
    "                    feature_1 = 1\n",
    "                if feature == 1:\n",
    "                    feature_1 = 0\n",
    "\n",
    "                y = np.mean(z_mean_growth[:,:,latent_z], axis= feature_1)\n",
    "                x = np.mean(Growth[:,:,feature], axis= feature_1)\n",
    "                col.plot(x, y)  \n",
    "\n",
    "                ## compute correlation and standardized covariance\n",
    "                corr = round(pearsonr(x,y)[0],3)\n",
    "                cov = round(np.cov(x, y)[0][1]/max(x),3)\n",
    "                col.annotate(\"corr:\"+str(corr)+\", cov:\"+str(cov), xy=(0, 1), xytext=(12, -12), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "\n",
    "        ## add row and column titles _____________________\n",
    "\n",
    "        rows = ['z_{}'.format(row) for row in range(z_mean_growth.shape[-1])]\n",
    "        cols = [t for t in growth_params]\n",
    "\n",
    "        for axis, col in zip(ax[0], cols):\n",
    "            axis.set_title(col, fontweight='bold')\n",
    "\n",
    "        for axis, row in zip(ax[:,0], rows):\n",
    "            axis.set_ylabel(row, rotation=0, size='large', fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "        ## 2.) Graph Topologies________________________________________________________\n",
    "\n",
    "        ## Visualize Latent Variables x Growth Parameters ____________________________\n",
    "\n",
    "        ##  Reshape Array according to Parameters  \n",
    "        #Topol = np.reshape(Topol,(n_config_graphs, n_config_graphs, -1))\n",
    "\n",
    "        fig, ax = plt.subplots(nrows= z_mean.shape[-1] , ncols= len(topol_params), figsize=(30,10))\n",
    "\n",
    "        for latent_z, row in enumerate(ax):        \n",
    "            for feature, col in enumerate(row):\n",
    "\n",
    "                ## toDO: change sorting\n",
    "                y = z_mean[:,latent_z]\n",
    "                x = Topol[:,feature]\n",
    "                sns.regplot(x, y, color=\"steelblue\", ax=col)\n",
    "                #col.scatter(x, y) \n",
    "\n",
    "                # set axes range\n",
    "                #plt.xlim(-4, 4)\n",
    "                #plt.ylim(-4, 4)\n",
    "\n",
    "               # try:\n",
    "               #     ## plot trend line\n",
    "               #     x = np.nan_to_num(x)\n",
    "               #     y = np.nan_to_num(y)\n",
    "\n",
    "               #     z = np.polyfit(x, y, 1)\n",
    "               #     p = np.poly1d(z)\n",
    "               #     col.plot(x,p(x),\"steelblue\")\n",
    "               # except:\n",
    "               #     pass\n",
    "\n",
    "\n",
    "                ## compute correlation and standardized covariance\n",
    "                corr = round(pearsonr(x,y)[0],3)\n",
    "                cov = round(np.cov(x, y)[0][1]/max(x),3)\n",
    "                col.annotate(\"corr:\"+str(corr)+\", cov:\"+str(cov), xy=(0, 1), xytext=(12, -12), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "\n",
    "\n",
    "        ## add row and column titles _____________________\n",
    "\n",
    "        rows = ['z_{}'.format(row) for row in range(z_mean.shape[-1])]\n",
    "        cols = [t for t in topol_params]\n",
    "\n",
    "        for axis, col in zip(ax[0], cols):\n",
    "            axis.set_title(col, fontweight='bold')\n",
    "\n",
    "        for axis, row in zip(ax[:,0], rows):\n",
    "            axis.set_ylabel(row, rotation=0, size='large', fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "## PLOT RESULTS ________________________________________\n",
    "\n",
    "analyzeArgs = {\"root_params\": 2, \"n_config_graphs\": 30, \"metric\": \"mig\"}\n",
    "latent_space_feature_correlation(analyzeArgs, modelArgs, dataArgs, models, batch_size=trainArgs[\"batch_size\"], model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Latent Space in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "analyzeArgs = {\"save_plots\": False}\n",
    "vis2D(analyzeArgs, modelArgs, models, data, batch_size=trainArgs[\"batch_size\"], model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Latent Generative Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "analyzeArgs = {\"z\": [0,1]}\n",
    "visDistr(modelArgs, analyzeArgs, models,data,trainArgs[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Single Graph Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "analyzeArgs = {\"activations\": [0, 0.2], \"z\": [0,1]}\n",
    "generate_single(analyzeArgs, modelArgs, dataArgs, models, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Interpolated Manifold from Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# range, normal, z\n",
    "analyzeArgs = {\"z\": [0,1], \"sample\": \"range\", \"act_range\": [-4, 4], \"act_scale\": 1, \"size_of_manifold\": 10, \"save_plots\": False}\n",
    "generate_manifold(analyzeArgs, modelArgs, dataArgs, models, data, color_map, batch_size=trainArgs[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Parameter Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from support.preprocessing import reconstruct_adjacency, unpad_matrix, sort_adjacency, pad_matrix\n",
    "\n",
    "import sys\n",
    "import networkx as nx\n",
    "from networkx.generators import random_graphs\n",
    "from networkx.generators import classic\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import os\n",
    "\n",
    "\n",
    "def decode_param(analyzeArgs, dataArgs, scaler, x_decoded):\n",
    "    ## generate graph from generative parameters\n",
    "    x_decoded = scaler.inverse_transform(x_decoded)\n",
    "    x_decoded = np.squeeze(x_decoded)\n",
    "    \n",
    "    \n",
    "    ## ensure data matches range\n",
    "    if analyzeArgs[\"graph_type\"] == \"Complete\":\n",
    "        n_gen = np.clip(int(x_decoded), 1, dataArgs[\"n_max\"] - 1)\n",
    "        g = classic.complete_graph(n_gen)\n",
    "\n",
    "        params = (\"n\")\n",
    "        y_pos = np.arange(len(params))\n",
    "        param_values = [n_gen / dataArgs[\"n_max\"]]\n",
    "\n",
    "        return g, y_pos, params, param_values\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## ensure data matches range\n",
    "    if analyzeArgs[\"graph_type\"] == \"Tree\":\n",
    "        b_gen = np.clip(int(x_decoded[0]), 1, dataArgs[\"n_max\"]-1)\n",
    "        h_gen = np.clip(int(x_decoded[1]), 1, dataArgs[\"n_max\"]-1)\n",
    "        g = classic.balanced_tree(b, h)\n",
    "\n",
    "        params = (\"b\", \"h\")\n",
    "        y_pos = np.arange(len(params))\n",
    "        param_values = [b_gen, h_gen]\n",
    "\n",
    "        return g, y_pos, params, param_values\n",
    "    \n",
    "    \n",
    "\n",
    "    ## ensure data matches range\n",
    "    if analyzeArgs[\"graph_type\"] == \"ER\":\n",
    "        n_gen = np.clip(int(x_decoded[0]), 1, dataArgs[\"n_max\"] - 1)\n",
    "        p_gen = np.clip(x_decoded[1], 0, 1)\n",
    "        g = random_graphs.erdos_renyi_graph(n_gen, p_gen, seed=None, directed=False)\n",
    "\n",
    "        params = (\"n\", \"p\")\n",
    "        y_pos = np.arange(len(params))\n",
    "        param_values = [n_gen / dataArgs[\"n_max\"], p_gen]\n",
    "\n",
    "        return g, y_pos, params, param_values\n",
    "    \n",
    "    \n",
    "    ## ensure data matches range\n",
    "    if analyzeArgs[\"graph_type\"] == \"PA\":\n",
    "        n_gen = np.clip(int(x_decoded[0]), 2, dataArgs[\"n_max\"] - 1)\n",
    "        e_gen = np.clip(int(x_decoded[1]), 1, n_gen-1)\n",
    "        g = random_graphs.barabasi_albert_graph(n_gen, e_gen, seed=None)\n",
    "\n",
    "        params = (\"n\", \"e\")\n",
    "        y_pos = np.arange(len(params))\n",
    "        param_values = [n_gen / dataArgs[\"n_max\"], e_gen / n_gen]\n",
    "\n",
    "        return g, y_pos, params, param_values\n",
    "\n",
    "\n",
    "\n",
    "    ## ensure data matches range\n",
    "    if analyzeArgs[\"graph_type\"] == \"HK\":\n",
    "        n_gen = np.clip(int(x_decoded[0]), 1, dataArgs[\"n_max\"] - 1)\n",
    "        e_gen = np.clip(int(x_decoded[1]), 1, n_gen)\n",
    "        p_gen = np.clip(x_decoded[2], 0, 1)\n",
    "        g = random_graphs.powerlaw_cluster_graph(n_gen, e_gen, p_gen, seed=None)\n",
    "\n",
    "        params = (\"n\", \"e\", \"p\")\n",
    "        y_pos = np.arange(len(params))\n",
    "        param_values = [n_gen / dataArgs[\"n_max\"], e_gen / n_gen, p_gen]\n",
    "\n",
    "        return g, y_pos, params, param_values\n",
    "\n",
    "\n",
    "\n",
    "    ## ensure data matches range\n",
    "    if analyzeArgs[\"graph_type\"] == \"SW\":\n",
    "        n_gen = np.clip(int(x_decoded[0]), 1, dataArgs[\"n_max\"] - 1)\n",
    "        k_gen = np.clip(int(x_decoded[1]), 0, n_gen-1)\n",
    "        p_gen = np.clip(x_decoded[2], 0, 1)\n",
    "        g = random_graphs.newman_watts_strogatz_graph(n_gen, k_gen, p_gen, seed=None) # no edges are removed\n",
    "\n",
    "        params = (\"n\", \"k\", \"p\")\n",
    "        y_pos = np.arange(len(params))\n",
    "        param_values = [n_gen / dataArgs[\"n_max\"], k_gen / n_gen, p_gen]\n",
    "\n",
    "        return g, y_pos, params, param_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_param_graph_manifold(analyzeArgs, modelArgs, dataArgs, models, data, color_map, batch_size, scaler):\n",
    "    # DECODER - Latent Space Interpolation____________________________\n",
    "\n",
    "    print(\"latent dimensions:\", modelArgs[\"latent_dim\"])\n",
    "\n",
    "    if modelArgs[\"param_loss\"] == False:\n",
    "        sys.exit(\"modelArgs[param_loss] should be True\")\n",
    "    else:\n",
    "        encoder, graph_decoder, param_decoder = models  # trained models\n",
    "\n",
    "    x_test, y_test = data\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, z_log_var, z = encoder.predict(x_test, batch_size)\n",
    "\n",
    "    ## Latent Space Dimension is 1 ______________________\n",
    "\n",
    "    if modelArgs[\"latent_dim\"] == 1:\n",
    "\n",
    "        ## 1) create adjacency plots__________________________________________\n",
    "\n",
    "        # display a 30x30 2D manifold of digits\n",
    "        n = dataArgs[\"n_max\"]  # number of nodes\n",
    "        figure = np.zeros((1 * n, analyzeArgs[\"size_of_manifold\"] * n))\n",
    "\n",
    "        # linearly spaced coordinates corresponding to the 2D plot\n",
    "        # of digit classes in the latent space\n",
    "        if analyzeArgs[\"sample\"] == \"z\":\n",
    "            grid_x = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][0]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "        elif analyzeArgs[\"sample\"] == \"range\":\n",
    "            grid_x = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])\n",
    "        elif analyzeArgs[\"sample\"] == \"normal\":\n",
    "            grid_x = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "\n",
    "        z_sample = np.zeros(modelArgs[\"latent_dim\"])\n",
    "        z_sample = np.reshape(z_sample, (1, modelArgs[\"latent_dim\"]))\n",
    "\n",
    "        ## 2) create graph plots_______________________________________________\n",
    "\n",
    "        fig, axs = plt.subplots(1, analyzeArgs[\"size_of_manifold\"], figsize=(10, 10))\n",
    "        # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample[0][0] = xi ** analyzeArgs[\"act_scale\"]\n",
    "            x_decoded = param_decoder.predict(z_sample)\n",
    "\n",
    "            g, y_pos, params, param_values = decode_param(analyzeArgs, dataArgs, scaler, x_decoded)\n",
    "\n",
    "            ## convert graph to adjacency\n",
    "            g, reconstructed_a = sort_adjacency(g)\n",
    "            reconstructed_a = pad_matrix(reconstructed_a, dataArgs[\"n_max\"], dataArgs[\n",
    "                \"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "\n",
    "            ## 1) create adjacency plot_____________________________\n",
    "\n",
    "            figure[0:n, j * n: (j + 1) * n] = reconstructed_a\n",
    "\n",
    "            ## 2) create graph plot_____________________________\n",
    "\n",
    "            # reconstruct graph\n",
    "            reconstructed_a = unpad_matrix(reconstructed_a, dataArgs[\"diag_value\"], dataArgs[\"fix_n\"])\n",
    "            g = nx.from_numpy_matrix(reconstructed_a)\n",
    "\n",
    "            # compute index for the subplot, and set this subplot as current\n",
    "            jx = np.unravel_index(j, axs.shape)\n",
    "            plt.sca(axs[jx])\n",
    "\n",
    "            nx.draw(g, node_size=10, node_color=color_map)\n",
    "            axs[jx].set_axis_off()\n",
    "            axs[jx].set(ylabel='z_0')\n",
    "\n",
    "        start_range = n // 2\n",
    "        end_range = (analyzeArgs[\"size_of_manifold\"] - 1) * n + start_range + 1\n",
    "        pixel_range = np.arange(start_range, end_range, n)\n",
    "        sample_range_x = np.round(grid_x, 1)\n",
    "\n",
    "        # Plot_____________________________\n",
    "\n",
    "        plt.figure(figsize=(15, 300))\n",
    "        plt.xticks(pixel_range, sample_range_x)\n",
    "        plt.xlabel(\"z_0\", fontweight='bold')\n",
    "        plt.imshow(figure, cmap='Greys_r')\n",
    "        plt.show()\n",
    "\n",
    "        if analyzeArgs[\"save_plots\"] == True:\n",
    "            filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "            plt.savefig(filename)\n",
    "\n",
    "    ## Latent Space Dimension is 2 ______________________\n",
    "\n",
    "    if modelArgs[\"latent_dim\"] == 2:\n",
    "\n",
    "        ## 1) create adjacency plots_______________________________________________\n",
    "\n",
    "        # display a 30x30 2D manifold of digits\n",
    "        n = dataArgs[\"n_max\"]  # number of nodes\n",
    "        figure = np.zeros((analyzeArgs[\"size_of_manifold\"] * n, analyzeArgs[\"size_of_manifold\"] * n))\n",
    "\n",
    "        # linearly spaced coordinates corresponding to the 2D plot\n",
    "        # of digit classes in the latent space\n",
    "        if analyzeArgs[\"sample\"] == \"z\":\n",
    "            grid_x = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][0]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][1]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "        elif analyzeArgs[\"sample\"] == \"range\":\n",
    "            grid_x = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])\n",
    "            grid_y = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])[::-1]  ## revert\n",
    "        elif analyzeArgs[\"sample\"] == \"normal\":\n",
    "            grid_x = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "\n",
    "        ## 2) create graph plots_______________________________________________\n",
    "\n",
    "        fig, axs = plt.subplots(analyzeArgs[\"size_of_manifold\"], analyzeArgs[\"size_of_manifold\"], figsize=(8, 8))\n",
    "        # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "        for i, yi in enumerate(grid_y):\n",
    "            for j, xi in enumerate(grid_x):\n",
    "                xi_value = xi ** analyzeArgs[\"act_scale\"]\n",
    "                yi_value = yi ** analyzeArgs[\"act_scale\"]\n",
    "\n",
    "                z_sample = np.array([[xi_value, yi_value]])\n",
    "                x_decoded = param_decoder.predict(z_sample)\n",
    "\n",
    "                g, y_pos, params, param_values = decode_param(analyzeArgs, dataArgs, scaler, x_decoded)\n",
    "\n",
    "                ## convert graph to adjacency\n",
    "                g, reconstructed_a = sort_adjacency(g)\n",
    "                reconstructed_a = pad_matrix(reconstructed_a, dataArgs[\"n_max\"], dataArgs[\n",
    "                    \"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "\n",
    "                ## 1) create adjacency plots_____________________________________\n",
    "\n",
    "                figure[i * n: (i + 1) * n, j * n: (j + 1) * n] = reconstructed_a\n",
    "\n",
    "                ## 2) create graph plot_____________________________\n",
    "\n",
    "                ## reconstruct graph\n",
    "                reconstructed_a = unpad_matrix(reconstructed_a, dataArgs[\"diag_value\"], dataArgs[\"fix_n\"])\n",
    "                g = nx.from_numpy_matrix(reconstructed_a)\n",
    "\n",
    "                # compute index for the subplot, and set this subplot as current\n",
    "                plt.sca(axs[i, j])\n",
    "                nx.draw(g, node_size=10, node_color=color_map)\n",
    "                axs[i, j].set_axis_off()\n",
    "\n",
    "        start_range = n // 2\n",
    "        end_range = (analyzeArgs[\"size_of_manifold\"] - 1) * n + start_range + 1\n",
    "        pixel_range = np.arange(start_range, end_range, n)\n",
    "        sample_range_x = np.round(grid_x, 1)\n",
    "        sample_range_y = np.round(grid_y, 1)\n",
    "\n",
    "        # Plot_____________________________\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.xticks(pixel_range, sample_range_x)\n",
    "        plt.yticks(pixel_range, sample_range_y)\n",
    "        plt.xlabel(\"z_0\", fontweight='bold')\n",
    "        plt.ylabel(\"z_1\", fontweight='bold')\n",
    "        plt.imshow(figure, cmap='Greys_r')\n",
    "        plt.show()\n",
    "\n",
    "        if analyzeArgs[\"save_plots\"] == True:\n",
    "            filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "            plt.savefig(filename)\n",
    "\n",
    "    ## Latent Space Dimension is larger than 2 ______________________\n",
    "\n",
    "    if modelArgs[\"latent_dim\"] > 2:\n",
    "\n",
    "        z_sample = np.zeros(modelArgs[\"latent_dim\"])\n",
    "        z_sample = np.reshape(z_sample, (1, modelArgs[\"latent_dim\"]))\n",
    "\n",
    "        ## fill unobserved dimensions with mean of latent variable dimension\n",
    "        for dim in range(0, len(z_sample[0])):\n",
    "            z_sample[0][dim] = np.mean(z_mean[:, dim])\n",
    "\n",
    "        ## 1) create adjacency plots_______________________________________________\n",
    "\n",
    "        # display a 30x30 2D manifold of digits\n",
    "        n = dataArgs[\"n_max\"]  # number of nodes\n",
    "        figure = np.zeros((analyzeArgs[\"size_of_manifold\"] * n, analyzeArgs[\"size_of_manifold\"] * n))\n",
    "\n",
    "        # linearly spaced coordinates corresponding to the 2D plot\n",
    "        # of digit classes in the latent space\n",
    "        if analyzeArgs[\"sample\"] == \"z\":\n",
    "            grid_x = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]),\n",
    "                                              np.mean(np.square(np.exp(z_log_var[:, analyzeArgs[\"z\"][0]]))),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]),\n",
    "                                              np.mean(np.square(np.exp(z_log_var[:, analyzeArgs[\"z\"][1]]))),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "        elif analyzeArgs[\"sample\"] == \"range\":\n",
    "            grid_x = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])\n",
    "            grid_y = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])[::-1]  ## revert\n",
    "        elif analyzeArgs[\"sample\"] == \"normal\":\n",
    "            grid_x = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "\n",
    "        ## 2) create graph plots_______________________________________________\n",
    "\n",
    "        fig, axs = plt.subplots(analyzeArgs[\"size_of_manifold\"], analyzeArgs[\"size_of_manifold\"], figsize=(10, 10))\n",
    "        # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "        for i, yi in enumerate(grid_y):\n",
    "            for j, xi in enumerate(grid_x):\n",
    "                z_sample[0][analyzeArgs[\"z\"][0]] = xi ** analyzeArgs[\"act_scale\"]\n",
    "                z_sample[0][analyzeArgs[\"z\"][1]] = xi ** analyzeArgs[\"act_scale\"]\n",
    "                x_decoded = param_decoder.predict(z_sample)\n",
    "\n",
    "                g, y_pos, params, param_values = decode_param(analyzeArgs, dataArgs, scaler, x_decoded)\n",
    "\n",
    "                ## convert graph to adjacency\n",
    "                g, reconstructed_a = sort_adjacency(g)\n",
    "                reconstructed_a = pad_matrix(reconstructed_a, dataArgs[\"n_max\"], dataArgs[\n",
    "                    \"diag_value\"])  # pad adjacency matrix to allow less nodes than n_max and fill diagonal\n",
    "                ## 1) create adjacency plot_____________________________\n",
    "\n",
    "                figure[i * n: (i + 1) * n,\n",
    "                j * n: (j + 1) * n] = reconstructed_a\n",
    "\n",
    "                ## 2) create graph plot_____________________________\n",
    "\n",
    "                ## reconstruct graph\n",
    "                reconstructed_a = unpad_matrix(reconstructed_a, dataArgs[\"diag_value\"], dataArgs[\"fix_n\"])\n",
    "                g = nx.from_numpy_matrix(reconstructed_a)\n",
    "\n",
    "                # compute index for the subplot, and set this subplot as current\n",
    "                plt.sca(axs[i, j])\n",
    "                nx.draw(g, node_size=10, node_color=color_map)\n",
    "                axs[i, j].set_axis_off()\n",
    "\n",
    "        start_range = n // 2\n",
    "        end_range = (analyzeArgs[\"size_of_manifold\"] - 1) * n + start_range + 1\n",
    "        pixel_range = np.arange(start_range, end_range, n)\n",
    "        sample_range_x = np.round(grid_x, 1)\n",
    "        sample_range_y = np.round(grid_y, 1)\n",
    "\n",
    "        # Plot_____________________________\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.xticks(pixel_range, sample_range_x)\n",
    "        plt.yticks(pixel_range, sample_range_y)\n",
    "        plt.xlabel(\"z_\" + str(analyzeArgs[\"z\"][0]), fontweight='bold')\n",
    "        plt.ylabel(\"z_\" + str(analyzeArgs[\"z\"][1]), fontweight='bold')\n",
    "        plt.imshow(figure, cmap='Greys_r')\n",
    "        plt.show()\n",
    "\n",
    "        if analyzeArgs[\"save_plots\"] == True:\n",
    "            filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "            plt.savefig(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_param_topol_manifold(analyzeArgs, modelArgs, dataArgs, models, data, color_map, batch_size, scaler):\n",
    "    print(\"latent dimensions:\", modelArgs[\"latent_dim\"])\n",
    "\n",
    "    if modelArgs[\"param_loss\"] == False:\n",
    "        sys.exit(\"modelArgs[param_loss] should be True\")\n",
    "    else:\n",
    "        encoder, graph_decoder, param_decoder = models  # trained models\n",
    "\n",
    "    x_test, y_test = data\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, z_log_var, z = encoder.predict(x_test, batch_size)\n",
    "\n",
    "    ## Latent Space Dimension is 1 ______________________\n",
    "\n",
    "    if modelArgs[\"latent_dim\"] == 1:\n",
    "\n",
    "        # linearly spaced coordinates corresponding to the 2D plot\n",
    "        # of digit classes in the latent space\n",
    "        if analyzeArgs[\"sample\"] == \"z\":\n",
    "            grid_x = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][0]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "        elif analyzeArgs[\"sample\"] == \"range\":\n",
    "            grid_x = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])\n",
    "        elif analyzeArgs[\"sample\"] == \"normal\":\n",
    "            grid_x = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "\n",
    "        z_sample = np.zeros(modelArgs[\"latent_dim\"])\n",
    "        z_sample = np.reshape(z_sample, (1, modelArgs[\"latent_dim\"]))\n",
    "\n",
    "        ## 1) create graph topol plots_______________________________________________\n",
    "\n",
    "        fig, axs = plt.subplots(1, analyzeArgs[\"size_of_manifold\"], figsize=(10, 10))\n",
    "        # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample[0][0] = xi ** analyzeArgs[\"act_scale\"]\n",
    "            x_decoded = param_decoder.predict(z_sample)\n",
    "\n",
    "            g, y_pos, params, param_values = decode_param(analyzeArgs, dataArgs, scaler, x_decoded)\n",
    "\n",
    "            # compute index for the subplot, and set this subplot as current\n",
    "            plt.sca(axs[j])\n",
    "\n",
    "            ## create the plot_____________________________________________\n",
    "\n",
    "            colors = [\"midnightblue\", \"steelblue\", \"skyblue\"]\n",
    "\n",
    "            plt.bar(y_pos, param_values, color=colors, align='center')\n",
    "            plt.plot([-1, 2], [0.25, 0.25], color='grey', linestyle='dashed')\n",
    "            plt.plot([-1, 2], [0.5, 0.5], color='grey', linestyle='dashed')\n",
    "            plt.plot([-1, 2], [0.75, 0.75], color='grey', linestyle='dashed')\n",
    "            plt.xticks(y_pos, params)\n",
    "\n",
    "            axs[xi].set_axis_off()\n",
    "\n",
    "        # import matplotlib.patches as mpatches\n",
    "\n",
    "        # density_patch = mpatches.Patch(color='midnightblue', label='density')\n",
    "        # cluster_patch = mpatches.Patch(color='blue', label='cluster_coef')\n",
    "        # assort_patch = mpatches.Patch(color='steelblue', label='assort')\n",
    "        # avg_degree_patch = mpatches.Patch(color='skyblue', label='avg_degree')\n",
    "        # axs[-1].legend(handles=[density_patch, cluster_patch, assort_patch, avg_degree_patch])\n",
    "\n",
    "        if analyzeArgs[\"save_plots\"] == True:\n",
    "            filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "            plt.savefig(filename)\n",
    "\n",
    "    if modelArgs[\"latent_dim\"] == 2:\n",
    "\n",
    "        # linearly spaced coordinates corresponding to the 2D plot\n",
    "        # of digit classes in the latent space\n",
    "        if analyzeArgs[\"sample\"] == \"z\":\n",
    "            grid_x = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][0]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][1]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "        elif analyzeArgs[\"sample\"] == \"range\":\n",
    "            grid_x = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])\n",
    "            grid_y = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])[::-1]  ## revert\n",
    "        elif analyzeArgs[\"sample\"] == \"normal\":\n",
    "            grid_x = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "\n",
    "        ## 1) create graph topol plots_______________________________________________\n",
    "\n",
    "        fig, axs = plt.subplots(analyzeArgs[\"size_of_manifold\"], analyzeArgs[\"size_of_manifold\"], figsize=(8, 8))\n",
    "        # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "        for i, yi in enumerate(grid_y):\n",
    "            for j, xi in enumerate(grid_x):\n",
    "                xi_value = xi ** analyzeArgs[\"act_scale\"]\n",
    "                yi_value = yi ** analyzeArgs[\"act_scale\"]\n",
    "\n",
    "                z_sample = np.array([[xi_value, yi_value]])\n",
    "                x_decoded = param_decoder.predict(z_sample)\n",
    "\n",
    "                g, y_pos, params, param_values = decode_param(analyzeArgs, dataArgs, scaler, x_decoded)\n",
    "\n",
    "                # compute index for the subplot, and set this subplot as current\n",
    "                plt.sca(axs[i, j])\n",
    "\n",
    "                ## create the plot_____________________________________________\n",
    "\n",
    "                colors = [\"midnightblue\", \"steelblue\", \"skyblue\"]\n",
    "\n",
    "                plt.bar(y_pos, param_values, color=colors, align='center')\n",
    "                plt.plot([-1, 2], [0.25, 0.25], color='grey', linestyle='dashed')\n",
    "                plt.plot([-1, 2], [0.5, 0.5], color='grey', linestyle='dashed')\n",
    "                plt.plot([-1, 2], [0.75, 0.75], color='grey', linestyle='dashed')\n",
    "                plt.xticks(y_pos, params)\n",
    "\n",
    "                axs[i, j].set_axis_off()\n",
    "\n",
    "        if analyzeArgs[\"save_plots\"] == True:\n",
    "            filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "            plt.savefig(filename)\n",
    "\n",
    "    if modelArgs[\"latent_dim\"] > 2:\n",
    "\n",
    "        z_sample = np.zeros(modelArgs[\"latent_dim\"])\n",
    "        z_sample = np.reshape(z_sample, (1, modelArgs[\"latent_dim\"]))\n",
    "\n",
    "        ## fill unobserved dimensions with mean of latent variable dimension\n",
    "        for dim in range(0, len(z_sample[0])):\n",
    "            z_sample[0][dim] = np.mean(z_mean[:, dim])\n",
    "\n",
    "        # linearly spaced coordinates corresponding to the 2D plot\n",
    "        # of digit classes in the latent space\n",
    "        if analyzeArgs[\"sample\"] == \"z\":\n",
    "            grid_x = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][0]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]),\n",
    "                                              np.mean(np.exp(z_log_var[:, analyzeArgs[\"z\"][1]])),\n",
    "                                              analyzeArgs[\"size_of_manifold\"]))\n",
    "        elif analyzeArgs[\"sample\"] == \"range\":\n",
    "            grid_x = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])\n",
    "            grid_y = np.linspace(analyzeArgs[\"act_range\"][0], analyzeArgs[\"act_range\"][1],\n",
    "                                 analyzeArgs[\"size_of_manifold\"])[::-1]  ## revert\n",
    "        elif analyzeArgs[\"sample\"] == \"normal\":\n",
    "            grid_x = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][0]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "            grid_y = np.sort(\n",
    "                np.random.normal(np.mean(z_mean[:, analyzeArgs[\"z\"][1]]), 1, analyzeArgs[\"size_of_manifold\"]))\n",
    "\n",
    "        ## 1) create graph topol plots_______________________________________________\n",
    "\n",
    "        fig, axs = plt.subplots(analyzeArgs[\"size_of_manifold\"], analyzeArgs[\"size_of_manifold\"], figsize=(10, 10))\n",
    "        # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "        for i, yi in enumerate(grid_y):\n",
    "            for j, xi in enumerate(grid_x):\n",
    "                z_sample[0][analyzeArgs[\"z\"][0]] = xi ** analyzeArgs[\"act_scale\"]\n",
    "                z_sample[0][analyzeArgs[\"z\"][1]] = xi ** analyzeArgs[\"act_scale\"]\n",
    "                x_decoded = param_decoder.predict(z_sample)\n",
    "\n",
    "                g, y_pos, params, param_values = decode_param(analyzeArgs, dataArgs, scaler, x_decoded)\n",
    "\n",
    "                # compute index for the subplot, and set this subplot as current\n",
    "                plt.sca(axs[i, j])\n",
    "\n",
    "                ## create the plot_____________________________________________\n",
    "\n",
    "                colors = [\"midnightblue\", \"steelblue\", \"skyblue\"]\n",
    "\n",
    "                plt.bar(y_pos, param_values, color=colors, align='center')\n",
    "                plt.plot([-1, 2], [0.25, 0.25], color='grey', linestyle='dashed')\n",
    "                plt.plot([-1, 2], [0.5, 0.5], color='grey', linestyle='dashed')\n",
    "                plt.plot([-1, 2], [0.75, 0.75], color='grey', linestyle='dashed')\n",
    "                plt.xticks(y_pos, params)\n",
    "\n",
    "                axs[i, j].set_axis_off()\n",
    "\n",
    "        if analyzeArgs[\"save_plots\"] == True:\n",
    "            filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "            plt.savefig(filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## range, normal, z\n",
    "analyzeArgs = {\"z\": [0,1], \"graph_type\": \"ER\", \"sample\": \"normal\", \"act_range\": [-4, 4], \"act_scale\": 1, \"size_of_manifold\": 10, \"save_plots\": False}\n",
    "generate_param_graph_manifold(analyzeArgs, modelArgs, dataArgs, models, data, color_map, trainArgs[\"batch_size\"], scaler)\n",
    "\n",
    "## \"cluster_coef\", \"assort\", \"avg_degree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_param_topol_manifold(analyzeArgs, modelArgs, dataArgs, models, data, color_map, trainArgs[\"batch_size\"], scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
